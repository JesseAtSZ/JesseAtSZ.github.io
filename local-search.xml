<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>Flink中的时间</title>
    <link href="/2022/06/02/Flink%E4%B8%AD%E7%9A%84%E6%97%B6%E9%97%B4/"/>
    <url>/2022/06/02/Flink%E4%B8%AD%E7%9A%84%E6%97%B6%E9%97%B4/</url>
    
    <content type="html"><![CDATA[<h2 id="流处理与批处理"><a href="#流处理与批处理" class="headerlink" title="流处理与批处理"></a>流处理与批处理</h2><p>流处理可以想象成有一条水流，只不过这条流里面流动的不是水而是数据。以京东统计销售额为例，想知道618当天的销售额是多少，有两种实现方法：</p><p><strong>批处理：</strong>在618当天结束的时候，统一进行分析处理，大概就是一个<em>select sum(amount) from trade</em>。用水流的例子，可以把水流的水（数据）都集中在一个大水箱里面，然后在某一时刻分析水（数据）的情况，但是这样的分析并不是实时的，只有当天结束的时候我们才能看到统计的数据。</p><p><strong>流处理：</strong>交易数据是源源不断的，一个接一个来，比如在00点00分01秒来了一个手机下单的交易数据，在00点00分02秒来了一个电视下单的交易数据，这些数据一个个来到，越积越多，我们迅速处理这些信息，没有延迟。就像在溪流的某个地方设立一个检测仪，检测水(数据）的实时情况，这样我们可以实时地看到统计数据。</p><h2 id="窗口"><a href="#窗口" class="headerlink" title="窗口"></a>窗口</h2><p>在上面这个场景中，我们需要面对的是连续不断、无休无止的无界流，但是我们只关心一段时间内数据的统计结果（618 00:00:00~618 23:59:59），在这种情况下，我们就可以定义一个窗口，收集最近618当天所有交易数据，然后进行统计，最终输出一个结果。</p><p>在 Flink 中, 窗口就是用来处理无界流的核心。可以把窗口想象成一个固定位置的“框”，数据源源不断地流过来，到某个时间点窗口该关闭了，就停止收集数据、触发计算并输出结果。</p><p>例如，我们定义一个时间窗口，每10秒统计一次数据，那么就相当于把窗口放在那里：</p><ul><li>从 0 秒开始收集数据；</li><li>到 10 秒时，处理当前窗口内所有数据，输出一个结果，然后清空窗口继续收集数据；</li><li>到 20 秒时，再对窗口内所有数据进行计算处理，输出结果；</li><li>依次类推；</li></ul><p><img src="/img/post/Flink_Window.png" alt="Flink Window"></p><p><strong>所谓的“窗口”，就是划定的一段时间范围；对在这范围内的数据进行处理，就是所谓的窗口计算。</strong></p><p><strong>窗口和时间往往是分不开的。</strong></p><h2 id="Flink-中的时间语义"><a href="#Flink-中的时间语义" class="headerlink" title="Flink 中的时间语义"></a>Flink 中的时间语义</h2><p>如果我们想要划定窗口来收集数据，一般就需要基于时间。对于批处理来说，因为数据都收集好了，想怎么划分窗口都可以；而对于流处理来说，如果想处理更加实时，就必须对时间有更加精细的控制。</p><p>在我们的认知里，只要有一个足够精确的表就可以告诉我们准确的时间了，在计算机系统里，对于一台机器而言，“时间”就是指系统时间。</p><pre><code>System.currentTimeMillis()</code></pre><p>但 Flink 是一个分布式处理系统，分布式架构最大的特点，就是节点彼此独立、互不影响，这带来了更高的吞吐量和容错性的同时，也会带来时间上的误差：</p><p><strong>在分布式系统中，节点“各自为政”，是没有统一时钟的，数据和控制信息都通过网络进行传输。</strong></p><p>比如现在有一个任务是窗口聚合，我们希望将每个小时的数据收集起来进行统计处理。而对于并行的窗口子任务，它们所在节点不同，系统时间也会有差异；当我们希望统计 8 点~9 点的数据时，对并行任务来说其实并不是“同时”的，收集到的数据也会有误差。</p><p>无法由 JobManager 来协调，因为网络传输会有延迟，且这延迟是不确定的，JobManager 发出的同步信号无法同时到达所有节点；</p><p>** 想要拥有一个全局统一的时钟，在分布式系统里是做不到的。**</p><p>另一个麻烦的问题是，在流式处理的过程中，数据是在不同的节点间不停流动的，这同样也会有网络传输的延迟。这样一来，当上下游任务需要跨节点传输数据时，它们对于“时间”的理解也会有所不同。</p><p>例如，上游任务在 8 点 59 分 59 秒发出一条数据，到下游要做窗口计算时已经是 9 点零 1 秒了，那这条数据到底该不该被收到 8 点~9 点的窗口呢？</p><p>所以，当我们希望对数据按照时间窗口来进行收集计算时，“时间”到底以谁为标准就非常重要了。</p><p><img src="/img/post/Flink_Time.svg" alt="Flink Time"></p><h4 id="两种时间语义"><a href="#两种时间语义" class="headerlink" title="两种时间语义"></a>两种时间语义</h4><p>上面的图片中，在事件发生之后，生成的数据被收集起来，首先进入分布式消息队列，然后被 Flink 系统中的 Source 算子读取消费，进而向下游的转换算子（窗口算子）传递，最终由窗口算子进行计算处理。</p><p>很明显，这里有两个非常重要的时间点：</p><p><strong>事件时间（Event Time）：一个是数据产生的时间</strong></p><p><strong>处理时间（Processing Time）：另一个是数据真正被处理的时刻</strong></p><p><strong>我们所定义的窗口操作，到底是以那种时间作为衡量标准，就是所谓的“时间语义”（Notionsof Time）。</strong></p><p>由于分布式系统中网络传输的延迟和时钟漂移，处理时间相对事件发生的时间会有所滞后。</p><p><strong>处理时间：</strong></p><p>处理时间的概念非常简单，就是指执行处理操作的机器的系统时间。</p><p>如果我们以它作为衡量标准，那么数据属于哪个窗口就很明显了：只看窗口任务处理这条数据时，当前的系统时间。</p><p>这种方法非常简单粗暴，不需要各个节点之间进行协调同步，也不需要考虑数据在流中的位置，简单来说就是“我的地盘听我的”。所以处理时间是最简单的时间语义。</p><p><strong>事件时间：</strong></p><p>事件时间，是指每个事件在对应的设备上发生的时间，也就是数据生成的时间。</p><p>在事件时间语义下，我们对于时间的衡量，就不看任何机器的系统时间了，而是依赖于数据本身。</p><p>相当于任务处理的时候自己本身是没有时钟的，所以只好来一个数据就问一下“现在几点了；</p><p>由于流处理中数据是源源不断产生的，一般来说，先产生的数据也会先被处理，所以当任务不停地接到数据时，它们的时间戳也基本上是不断增长的，就可以代表时间的推进。</p><p>数据一旦产生，这个时间自然就确定了，所以它可以作为一个属性嵌入到数据中。这其实就是这条数据记录的“时间戳”（Timestamp）。</p><p>当然，这里有个前提，就是“先产生的数据先被处理”，这要求我们可以保证数据到达的顺序。</p><p>但是由于分布式系统中网络传输延迟的不确定性，实际应用中我们要面对的数据流往往是乱序的。在这种情况下，就不能简单地把数据自带的时间戳当作时钟了，而需要用另外的标志来表示事件时间进展，在 Flink 中把它叫作事件时间的“水位线”（Watermarks）。</p><h4 id="哪种时间语义更重要"><a href="#哪种时间语义更重要" class="headerlink" title="哪种时间语义更重要"></a>哪种时间语义更重要</h4><p><img src="/img/post/Flink_Star_Wars.png" alt="Star Wars"></p><p>看电影其实就是处理影片中数据的过程，所以影片的上映时间就相当于“处理时间”<br>而影片的数据就是所描述的故事，它所发生的背景时间就相当于“事件时间”<br>选择哪种观影顺序？</p><ul><li><p><strong>剧情党？</strong></p></li><li><p><strong>特效党？</strong></p></li></ul><p><strong>两种时间语义都有各自的用途，适用于不同的场景。</strong></p><p><strong>处理时间：</strong></p><p>由于网络延迟，导致数据到达各个算子任务的时间有快有慢，对于窗口操作就可能收集不到正确的数据了，数据处理的顺序也会被打乱。这就会影响到计结果的正确性。</p><p>这种方式可以让我们的流处理延迟降到最低，效率达到最高，一般用在对实时性要求极高、而对计算准确性要求不太高的场景。</p><p><strong>事件时间：</strong></p><p>水位线成为了时钟，可以统一控制时间的进度。这就保证了总可以将数据划分到正确的窗口中，但我们知道数据还可能是乱序的，要想让窗口正确地收集到所有数据，就必须等这些错乱的数据都到齐，这就需要一定的等待时间。</p><p>事件时间语义是以一定延迟为代价，换来了处理结果的正确性。</p><p><strong>由于网络延迟一般只有毫秒级，所以即使是事件时间语义，同样可以完成低延迟实时流处理的任务。</strong></p><p>在 Flink 中，由于处理时间比较简单，早期版本默认的时间语义是处理时间；而考虑到事件时间在实际应用中更为广泛，从 1.12 版本开始，Flink 已经将事件时间作为了默认的时间语义。</p><h2 id="水位线（Watermark）"><a href="#水位线（Watermark）" class="headerlink" title="水位线（Watermark）"></a>水位线（Watermark）</h2><h4 id="事件时间和窗口的关系"><a href="#事件时间和窗口的关系" class="headerlink" title="事件时间和窗口的关系"></a>事件时间和窗口的关系</h4><p><strong>举个例子：将生产线上生产的商品，发车运送，要求每个小时生产的商品对应一个车次，一辆车就只装载 1 小时内生产出的所有商品，货到齐了就发车。</strong></p><p><strong>怎么明确货物所属的车次（明确数据所属的窗口）？</strong></p><p>事件时间是一个数据产生的时刻，就是流处理中事件触发的时间点，一般都会以时间戳的形式作为一个字段记录在数据里。如果我们想要统计一段时间内的数据，需要划分时间窗口，这时只要判断一下时间戳就可以知道数据属于哪个窗口了。</p><p><strong>司机什么时候发车（等待窗口中的数据到齐）？</strong></p><p>窗口处理的是有界数据，我们需要等窗口的数据都到齐了，才能计算出最终的统计结果。那什么时候数据就都到齐了呢？对于时间窗口来说这很明显：到了窗口的结束时间，自然就应该收集到了所有数据，就可以触发计算输出结果了。</p><p><strong>怎么确定这个批次的货物都到齐了（时间的确定）？</strong></p><p>处理时间：以当前任务所在节点的系统时间为准</p><p>事件时间：以数据中携带的时间戳为准</p><p><img src="/img/post/Flink_Window_Close_And_Open.png" alt="Flink Window Open And Close"></p><p>在这个处理过程中，我们其实是基于数据的时间戳，自定义了一个“逻辑时钟”。这个时钟的时间不会自动流逝；它的时间进展，就是靠着新到数据的时间戳来推动的。这样的好处在于，计算的过程可以完全不依赖处理时间（系统时间），不论什么时候进行统计处理，得到的结果都是正确的。</p><p>比如 618 的时候系统处理压力大，可能会把大量数据缓存在 Kafka 中；过了高峰时段之后再读取出来，在几秒之内就可以处理完几个小时甚至几天的数据，而且依然可以按照数据产生的时间段进行统计，所有窗口都能收集到正确的数据。</p><p>一般实时流处理的场景中，事件时间可以基本与处理时间保持同步，只是略微有一点延迟，同时保证了窗口计算的正确性。</p><h4 id="什么是水位线？"><a href="#什么是水位线？" class="headerlink" title="什么是水位线？"></a>什么是水位线？</h4><p>在事件时间语义下，我们不依赖系统时间，而是基于数据自带的时间戳去定义了一个时钟，用来表示当前时间的进展。于是每个并行子任务都会有一个自己的逻辑时钟，它的前进是靠数据的时间戳来驱动的。</p><p><strong>分布式系统下遇到的问题：</strong></p><ul><li><strong>遇到窗口聚合操作时，要攒一批数据才会输出一个结果，所以时间进度的控制不够精细</strong></li><li><strong>数据向下游任务传递时，一般只能传输给一个子任务，这样其他的并行子任务的时钟就无法推进了</strong></li></ul><p>一种简单的解决方法是，在数据流中加入一个时钟标记，记录当前的事件时间；这个标记可以直接广播到下游，当下游任务收到这个标记，就可以更新自己的时钟了。由于类似于水流中用来做标志的记号，在 Flink 中，这种用来衡量事件时间（Event Time）进展的标记，就被称作“水位线”（Watermark）。</p><p><strong>水位线可以看作一条特殊的数据记录，它是插入到数据流中的一个标记点，主要内容就是一个时间戳，用来指示当前的事件时间。而它插入流中的位置，就应该是在某个数据到来之后，这样就可以从这个数据中提取时间戳，作为当前水位线的时间戳了。</strong></p><p><img src="/img/post/Flink_Watermark.png" alt="Flink Watermark"></p><h4 id="有序流中的水位线"><a href="#有序流中的水位线" class="headerlink" title="有序流中的水位线"></a>有序流中的水位线</h4><p>有序流是一种理想状态，数据按照顺序进入流，而且处理的过程中也会保持原先的顺序不变。</p><p>每条数据后都插入水位线会导致效率问题：</p><ul><li><strong>如果当前数据量非常大，可能会有很多数据的时间戳是相同的</strong></li><li><strong>同时涌来的数据时间差会非常小（比如几毫秒），往往对处理计算也没什么影响</strong></li></ul><p>所以为了提高效率，一般会每隔一段时间生成一个水位线，这个水位线的时间戳，就是当前最新数据的时间戳，所以这时的水位线，其实就是有序流中的一个周期性出现的时间标记。</p><p>![Watermark In Ordered Flow](/img/post/Watermark In Ordered Flow.png)</p><p>需要注意的是，对于水位线的周期性生成，周期时间是指处理时间（系统时间），而不是事件时间。</p><h4 id="无序流中的水位线"><a href="#无序流中的水位线" class="headerlink" title="无序流中的水位线"></a>无序流中的水位线</h4><p>在分布式系统中，数据在节点间传输，会因为网络传输延迟的不确定性，导致顺序发生改变，即“乱序数据”。</p><p>![Watermark In Disordered Flow](/img/post/Watermark In Disordered Flow 01.png)</p><p>如果还是和之前一样，靠数据来驱动，每来一个数据就提取它的时间戳、插入一个水位线，那么有可能新的时间戳比之前的还小，直接将这个时间的水位线再插入，“时钟”就回退了，但是水位线代表时钟，时光不能倒流，水位线的时间戳也不能减小。</p><p>所以插入新的水位线时，要先判断一下时间戳是否比之前的大，否则就不再生成新的水位线，也就是说，只有数据的时间戳比当前时钟大，才能推动时钟前进，这时才插入水位线。</p><p>![Watermark In Disordered Flow](/img/post/Watermark In Disordered Flow 02.png)</p><p>如果考虑到大量数据同时到来的处理效率，同样可以周期性地生成水位线。这时只需要保存一下之前所有数据中的最大时间戳，需要插入水位线时，就直接以它作为时间戳生成新的水位线。</p><p>![Watermark In Disordered Flow](/img/post/Watermark In Disordered Flow 03.png)</p><h4 id="迟到数据的处理"><a href="#迟到数据的处理" class="headerlink" title="迟到数据的处理"></a>迟到数据的处理</h4><p>上面的例子中，当 9 秒产生的数据到来之后，我们就直接将时钟推进到了9 秒；如果有一个窗口结束时间就是 9 秒，那么这时窗口就应该关闭、将收集到的所有数据计算输出结果了。</p><p>但事实上，由于数据是乱序的，还可能有时间戳为 7 秒、8 秒的数据在 9 秒的数据之后才到来，这就是“迟到数据”（late data）。</p><p>回到生产线发货的例子，商品不是按照生产时间顺序到来的，所以有可能 9 点生产的商品已经到了，司机认为已经到了9 点，所以直接发车；但是可能还会有8 点 59 分59 秒生产的商品迟到了，没有赶上这班车。</p><p>解决办法就是稍微等一会儿：9 点发车，可以等到 9 点10分，等货物都到齐了再出发。</p><p>为了做到形式上仍然是9 点发车，可以更改一下时钟推进的逻辑：当一个货品到达时，不要直接用它的生产时间作为当前时间，而是减上两秒，这就相当于把车上的逻辑时钟调慢了（把司机手上的表调慢两秒）。</p><p>回到上面的例子，为了让窗口能够正确收集到迟到的数据，也可以等上2 秒；也就是用当前已有数据的最大时间戳减去 2 秒，就是要插入的水位线的时间戳，这样的话，9 秒的数据到来之后，事件时钟不会直接推进到 9 秒，而是进展到了7 秒；必须等到11 秒的数据到来之后，事件时钟才会进展到 9 秒，这时迟到数据也都已收集齐，0~9 秒的窗口就可以正确计算结果了。</p><p>![Late Data](/img/post/Late Data.png)</p><p>这里等待两秒是依据我们的经验，未必能处理所有的乱序数据。</p><p>解决方法是可以试着再多等几秒，也就是把时钟调得更慢一些。最终的目的，就是要让窗口能够把所有迟到数据都收进来，得到正确的计算结果。</p><p>对应到水位线上，其实就是要保证，<strong>当前时间已经进展到了这个时间戳，在这之后不可能再有迟到数据来了</strong>。</p><h4 id="水位线的特性"><a href="#水位线的特性" class="headerlink" title="水位线的特性"></a>水位线的特性</h4><p>水位线就代表了当前的事件时间时钟，而且可以在数据的时间戳基础上加一些延迟来保证不丢数据，这一点对于乱序流的正确处理非常重要。</p><ul><li>水位线是插入到数据流中的一个标记，可以认为是一个特殊的数据</li><li>水位线主要的内容是一个时间戳，用来表示当前事件时间的进展</li><li>水位线是基于数据的时间戳生成的</li><li>水位线的时间戳必须单调递增，以确保任务的事件时间时钟一直向前推进</li><li>水位线可以通过设置延迟，来保证正确处理乱序数据</li><li>一个水位线Watermark(t)，表示在当前流中事件时间已经达到了时间戳 t, 这代表t 之前的所有数据都到齐了，之后流中不会出现时间戳 t’ ≤ t 的数据 </li></ul><h4 id="如何生成水位线"><a href="#如何生成水位线" class="headerlink" title="如何生成水位线"></a>如何生成水位线</h4><p>水位线是用来保证窗口处理结果的正确性的，如果不能正确处理所有乱序数据，可以尝试调大延迟的时间，但是具体应该怎么生成水位呢？</p><p>对于水位线，只能尽量取保证正确，想保证正确性只能等，由于网络传输延迟的不确定，为了获取所有迟到的数据，只能等待更长时间。</p><p>具体等多长时间，需要我们对相关领域有一定的了解，比如我们知道当前业务中事件迟到的时间不会超过 5 秒，那就把水位线的时间戳设为当前已有数据的最大时间戳减去5 秒，相当于设置了 5 秒的延迟等待。</p><ul><li><p>如果我们希望计算结果能更加准确，那可以将水位线的延迟设置得更高一些，等待的时间越长，自然也就越不容易漏掉数据。不过这样做的代价是处理的实时性降低了，我们可能为极少数的迟到数据增加了很多不必要的延迟。</p></li><li><p>如果我们希望处理得更快、实时性更强，那么可以将水位线延迟设得低一些。这种情况下，可能很多迟到数据会在水位线之后才到达，就会导致窗口遗漏数据，计算结果不准确。对于这些 “漏网之鱼”。当然，如果对准确性完全不考虑、一味地追求处理速度，可以直接使用处理时间语义，这在理论上可以得到最低的延迟。 </p></li></ul><p><strong>Flink 中的水位线，其实是流处理中对低延迟和结果正确性的一个权衡机制，而且把控制的权力交给了程序员</strong>。</p><h3 id="水位线的传递"><a href="#水位线的传递" class="headerlink" title="水位线的传递"></a>水位线的传递</h3><p><strong>直通式传输</strong>：数据和水位线都是按照本身的顺序依次传递、依次处理的，一旦水位线到达了算子任务, 那么这个任务就会将它内部的时钟设为这个水位线的时间戳。 </p><p><strong>广播式传输</strong>：下游有多个并行子任务，那么上游任务处理完水位线，时钟改变之后，要把当前的水位线再次发出，广播给所有的下游子任务。</p><p><strong>重分区传输</strong>：</p><p><strong>水位线定义的本质：它表示的是“当前时间之前的数据，都已经到齐了”</strong>。</p><p>如果一个任务收到了来自上游并行任务的不同的水位线，说明上游各个分区处理得有快有慢，这时我们要以“这之前的数据全部到齐”为标准（木桶原理？）。</p><p>![Watermark Transmit](/img/post/Watermark Transmit.png)</p><h2 id="水位线的总结"><a href="#水位线的总结" class="headerlink" title="水位线的总结"></a>水位线的总结</h2><ul><li><strong>水位线在事件时间的世界里面，承担了时钟的角色</strong></li><li><strong>水位线是一种特殊的事件，由程序员通过编程插入的数据流里面，然后跟随数据流向下游流动</strong></li><li><strong>不同的算子看到的水位线的大小可能是不一样的（下游的算子可能并未接收到来自上游算子的水位线，导致下游算子的时钟要落后于上游算子的时钟）</strong></li></ul><hr><p><strong>水位线的重要性在于它的逻辑时钟特性，而逻辑时钟这个概念可以说是分布式系统里面最为重要的概念之一了，理解水位线对理解各种分布式系统非常有帮助。</strong></p>]]></content>
    
    
    <categories>
      
      <category>Flink</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Flink</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Flink 并行度、算子链及执行图</title>
    <link href="/2022/05/17/Flink-%E5%B9%B6%E8%A1%8C%E5%BA%A6%E3%80%81%E7%AE%97%E5%AD%90%E9%93%BE%E5%8F%8A%E6%89%A7%E8%A1%8C%E5%9B%BE/"/>
    <url>/2022/05/17/Flink-%E5%B9%B6%E8%A1%8C%E5%BA%A6%E3%80%81%E7%AE%97%E5%AD%90%E9%93%BE%E5%8F%8A%E6%89%A7%E8%A1%8C%E5%9B%BE/</url>
    
    <content type="html"><![CDATA[<h2 id="Flink-集群"><a href="#Flink-集群" class="headerlink" title="Flink 集群"></a>Flink 集群</h2><p>Flink 运行时由两种类型的进程组成：一个 JobManager 和一个或者多个 TaskManager。</p><p><img src="/img/post/Flink.svg" alt="Flink"></p><p>Client 不是运行时和程序执行的一部分，而是用于准备数据流并将其发送给 JobManager。之后，客户端可以断开连接（detached mode），或保持连接来接收进程报告（attached mode）。客户端可以作为触发执行 Java/Scala 程序的一部分运行，也可以在命令行进程./bin/flink run …中运行。</p><p><strong>客户端它只负责作业的提交。具体来说，就是调用程序的 main 方法，将代码转换成“数据流图”（Dataflow Graph），并最终生成作业图（JobGraph），一并发送给 JobManager。</strong></p><p>可以通过多种方式启动 JobManager 和 TaskManager：直接在机器上作为 Standalone 集群启动、在容器中启动、或者通过 YARN 等资源框架管理并启动。TaskManager 连接到 JobManagers，宣布自己可用，并被分配工作。</p><h2 id="JobManager"><a href="#JobManager" class="headerlink" title="JobManager"></a>JobManager</h2><p>JobManager 具有许多与协调 Flink 应用程序的分布式执行有关的职责：它决定何时调度下一个 task（或一组 task）、对完成的 task 或执行失败做出反应、协调 checkpoint、并且协调从失败中恢复等等。这个进程由三个不同的组件组成：</p><ul><li><strong>JobMaster</strong></li></ul><p>JobMaster 负责管理单个JobGraph 的执行。Flink 集群中可以同时运行多个作业（Job），每个作业都有自己的 JobMaster。JobMaster 是 JobManager 中最核心的组件，负责处理单独的作业（Job）。所以 JobMaster 和具体的 Job 是一一对应的，多个 Job 可以同时运行在一个 Flink 集群中, 每个 Job 都有一个自己的 JobMaster。</p><p>需要注意在早期版本的 Flink 中，没有 JobMaster 的概念；而 JobManager 的概念范围较小，实际指的就是现在所说的 JobMaster。</p><p>在作业提交时，JobMaster 会先接收到要执行的应用。这里所说“应用”一般是客户端提交来的，包括：Jar 包，数据流图（dataflow graph），和作业图（JobGraph）。</p><p>JobMaster 会把 JobGraph 转换成一个物理层面的数据流图，这个图被叫作“执行图”（ExecutionGraph），它包含了所有可以并发执行的任务。 JobMaster 会向资源管理器（ResourceManager）发出请求，申请执行任务必要的资源。一旦它获取到了足够的资源，就会将执行图分发到真正运行它们的 TaskManager 上。而在运行过程中，JobMaster 会负责所有需要中央协调的操作，比如说检查点（checkpoints）的协调。</p><ul><li><strong>ResourceManager</strong></li></ul><p>ResourceManager 负责 Flink 集群中的资源提供、回收、分配 - 它管理 task slots，这是 Flink 集群中资源调度的单位。Flink 为不同的环境和资源提供者（例如 YARN、Kubernetes 和 Standalone 部署）实现了对应的 ResourceManager。在 Standalone 设置中，ResourceManager 只能分配可用 TaskManager 的 slots，而不能自行启动新的 TaskManager。</p><p>所谓“资源”，主要是指 TaskManager 的任务槽（task slots）。任务槽就是 Flink 集群中的资源调配单元，包含了机器用来执行计算的一组 CPU 和内存资源。每一个任务（Task）都需要分配到一个 slot 上执行。</p><ul><li><strong>Dispatcher</strong></li></ul><p>Dispatcher 提供了一个 REST 接口，用来提交 Flink 应用程序执行，并为每个提交的作业启动一个新的 JobMaster。它还运行 Flink WebUI 用来提供作业执行信息。</p><p>Dispatcher 在架构中并不是必需的，在不同的部署模式下可能会被忽略掉。</p><p>集群中至少有一个 JobManager。高可用（HA）下可以设置多个 JobManager，其中一个始终是 leader，其他的则是 standby。</p><h2 id="TaskManagers"><a href="#TaskManagers" class="headerlink" title="TaskManagers"></a>TaskManagers</h2><p>TaskManager 是 Flink 中的工作进程，数据流的具体计算就是它来做的，所以也被称为“Worker”。</p><p>集群中至少有一个 TaskManager。在 TaskManager 中资源调度的最小单位是 task slot。TaskManager 中 task slot 的数量表示并发处理 task 的数量，一个 task slot 中可以执行多个算子。</p><p>Slot是资源调度的最小单位，slot 的数量限制了 TaskManager 能够并行处理的任务数量。</p><p>启动之后，TaskManager 会向资源管理器注册它的 slots；收到资源管理器的指令后，TaskManager 就会将一个或者多个槽位提供给 JobMaster 调用，JobMaster 就可以分配任务来执行了。</p><p>在执行过程中，TaskManager 可以缓冲数据，还可以跟其他运行同一应用的 TaskManager</p><p>交换数据。</p><h2 id="作业提交流程"><a href="#作业提交流程" class="headerlink" title="作业提交流程"></a>作业提交流程</h2><p><img src="/img/post/Flink_Job.png" alt="Flink Job"></p><ol><li>一般情况下，由客户端（App）通过 Dispatcher 提供的 REST 接口，将作业提交给 JobManager。</li><li>由 Dispatcher 启动 JobMaster，并将作业（包含 JobGraph）提交给 JobMaster。</li><li>JobMaster 将 JobGraph 解析为可执行的 ExecutionGraph，得到所需的资源数量，然后向资源管理器请求资源（slots）。</li><li>资源管理器判断当前是否由足够的可用资源；如果没有，启动新的 TaskManager。</li><li>TaskManager 启动之后，向 ResourceManager 注册自己的可用任务槽（slots）。</li><li>资源管理器通知 TaskManager 为新的作业提供 slots。</li><li>TaskManager 连接到对应的 JobMaster，提供 slots。</li><li>JobMaster 将需要执行的任务分发给 TaskManager。</li><li>askManager 执行任务，互相之间可以交换数据。</li></ol><h2 id="并行度"><a href="#并行度" class="headerlink" title="并行度"></a>并行度</h2><p>把一个算子操作，“复制”多份到多个节点，数据来了之后就可以到其中任意一个执行。这样一来，一个算子任务就被拆分成了多个并行的“子任务”（subtasks），再将它们分发到不同节点，就真正实现了并行计算。</p><p>在 Flink 执行过程中，每一个算子（operator）可以包含一个或多个子任务（operator subtask），这些子任务在不同的线程、不同的物理机或不同的容器中完全独立地执行。</p><p>一个特定算子的子任务（subtask）的个数被称之为其并行度（parallelism）。这样，包含并行子任务的数据流，就是并行数据流，它需要多个分区（stream partition）来分配并行任务。</p><p>一般情况下，一个流程序的并行度，可以认为就是其所有算子中最大的并行度。一个程序中，不同的算子可能具有不同的并行度。</p><h2 id="算子间的数据传输"><a href="#算子间的数据传输" class="headerlink" title="算子间的数据传输"></a>算子间的数据传输</h2><p>一个数据流在算子之间传输数据的形式可以是一对一（one-to-one）的直通 (forwarding)模式，也可以是打乱的重分区（redistributing）模式，具体是哪一种形式，取决于算子的种类。</p><ul><li><strong>一对一（One-to-one，forwarding）</strong></li></ul><p>这种模式下，数据流维护着分区以及元素的顺序。比如图中的 source 和 map 算子，source 算子读取数据之后，可以直接发送给 map 算子做处理，它们之间不需要重新分区，也不需要调整数据的顺序。这就意味着 map 算子的子任务，看到的元素个数和顺序跟 source 算子的子任务产生的完全一样，保证着“一对一”的关系。map、filter、flatMap 等算子都是这种 one-to-one的对应关系。</p><ul><li><strong>重分区（Redistributing）</strong></li></ul><p>在这种模式下，数据流的分区会发生改变。比图中的 map 和后面的 keyBy/window 算子之间（这里的 keyBy 是数据传输算子，后面的 window、apply 方法共同构成了 window 算子），以及 keyBy/window 算子和 Sink 算子之间，都是这样的关系。每一个算子的子任务，会根据数据传输的策略，把数据发送到不同的下游目标任务。例如，keyBy() 是分组操作，本质上基于键（key）的哈希值（hashCode）进行了重分区；而当并行度改变时，比如从并行度为 2 的 window 算子，要传递到并行度为 1 的 Sink 算子，这时的数据传输方式是再平衡（rebalance），会把数据均匀地向下游子任务分发出去。</p><h2 id="Tasks-和算子链"><a href="#Tasks-和算子链" class="headerlink" title="Tasks 和算子链"></a>Tasks 和算子链</h2><p>对于分布式执行，一个特定 operator 的 subtask 的个数被称之为其并行度（parallelism），程序开发过程中可以对单独的每个 operator 进行并行度设置，也可以直接用 env 设置全局的并行度，更常用的方式是在 WebUI 提交任务时去指定并行度。</p><p>并行度相同的一对一（one to one）算子操作，可以直接链接在一起形成一个“大”的任务（task），这样原来的算子就成为了真正任务里的一部分。每个 task 会被一个线程执行。这样的技术被称为“算子链”（Operator Chain）。</p><p>将算子链接成 task 是非常有效的优化：可以减少线程之间的切换和基于缓存区的数据交换，在减少时延的同时提升吞吐量。</p><p>Flink 默认会按照算子链的原则进行链接合并，如果我们想要禁止合并或者自行定义，也可以在代码中对算子做一些特定的设置：Task Chaining and Resource Groups</p><p>下图中数据流用 5 个 subtask 执行，因此有 5 个并行线程（上图为数据流的逻辑视图，下图为数据流的并行视图）：</p><p><img src="/img/post/Flink_Tasks_Chains.svg" alt="Flink Tasks Chains"></p><h2 id="Task-Slots-和资源"><a href="#Task-Slots-和资源" class="headerlink" title="Task Slots 和资源"></a>Task Slots 和资源</h2><p>每个 worker（TaskManager）都是一个 JVM 进程，可以在单独的线程中执行一个或多个 subtask。为了控制一个 TaskManager 中接受多少个 task，就有了所谓的 task slots（至少一个）。</p><p>每个 task slot 代表 TaskManager 中资源的固定子集。例如，具有 3 个 slot 的 TaskManager，会将其托管内存 1/3 用于每个 slot。分配资源意味着 subtask 不会与其他作业的 subtask 竞争内存，而是一直持有一定数量内存。注意 CPU 没有进行隔离，目前 slot 仅对托管的内存进行了隔离。</p><p>如果一个 TaskManager 只有一个 slot，那将意味着每个任务都会运行在独立的JVM 中（当然，该 JVM 可能是通过一个特定的容器启动的）；而一个 TaskManager 设置多个slot 则意味着多个子任务可以共享同一个 JVM。它们的区别在于：前者任务之间完全独立运行，<br>隔离级别更高、彼此间的影响可以降到最小；而后者在同一个 JVM 进程中运行的任务，将共享 TCP 连接和心跳消息，也可能共享数据集和数据结构，这就减少了每个任务的运行开销，在降低隔离级别的同时提升了性能。需要注意的是，slot 目前仅仅用来隔离内存，不会涉及 CPU 的隔离。在具体应用时，可以将 slot 数量配置为机器的 CPU 核心数，尽量避免不同任务之间对 CPU 的竞争。这也是开发环境默认并行度设为机器 CPU 数量的原因。</p><p><img src="/img/post/Flink_Tasks_Slots.svg" alt="Flink Tasks Slots"></p><p>Flink 是允许子任务共享 slot 的。只要属于同一个作业，那么对于不同任务节点的并行子任务，就可以放到同一个 slot 上执行。</p><p>所以下图中，对于第一个任务节点 source→map，它的 6 个并行子任务必须分到不同的 slot 上（如果在同一 slot 就没法数据并行了），而第二个任务节点 keyBy/window/apply 的并行子任务却可以和第一个任务节点共享 slot。</p><p>于是最终结果就变成了：每个任务节点的并行子任务一字排开，占据不同的 slot；而不同的任务节点的子任务可以共享 slot。一个 slot 中，可以将程序处理的所有任务都放在这里执行，把它叫作保存了整个作业的运行管道（pipeline）。</p><p>一个 slot 对应了一组独立的计算资源。在之前不做共享的时候，每个任务都平等地占据了一个 slot，但其实不同的任务对资源的占用是不同的。例如这里的前两个任务，source/map 尽管是两个算子合并算子链得到的，但它只是基本的数据读取和简单转换，计算耗</p><p>时极短，一般也不需要太大的内存空间；而 window 算子所做的窗口操作，往往会涉及大量的数据、状态存储和计算，我们一般把这类任务叫作“资源密集型”（intensive）任务。当它们被平等地分配到独立的 slot 上时，实际运行我们就会发现，大量数据到来时 source/map 和 sink 任务很快就可以完成，但 window 任务却耗时很久；于是下游的 sink 任务占据的 slot 就会等待闲置，而上游的 source/map 任务受限于下游的处理能力，也会在快速处理完一部分数据后阻塞对应的资源开始等待（相当于处理背压）。这样资源的利用就出现了极大的不平衡，“忙的忙死，闲的闲死”。解决这一问题的思路就是允许 slot 共享。将资源密集型和非密集型的任务同时放到一个 slot 中，它们就可以自行分配对资源占用的比例，从而保证最重的活平均分配给所有的 TaskManager。</p><p>slot 共享另一个好处就是允许我们保存完整的作业管道。这样一来，即使某个 TaskManager 出现故障宕机，其他节点也可以完全不受影响，作业的任务可以继续执行。</p><p>另外，同一个任务节点的并行子任务是不能共享 slot 的，所以允许 slot 共享之后，运行作业所需的 slot 数量正好就是作业中所有算子并行度的最大值。</p><p><img src="/img/post/Flink_Slot_Sharing.svg" alt="Flink Slot Sharing"></p>]]></content>
    
    
    <categories>
      
      <category>Flink</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Flink</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>MySQL BinLog 更新</title>
    <link href="/2022/03/15/MySQL-BinLog-%E6%9B%B4%E6%96%B0/"/>
    <url>/2022/03/15/MySQL-BinLog-%E6%9B%B4%E6%96%B0/</url>
    
    <content type="html"><![CDATA[<p><strong>参考资料：<a href="https://dev.mysql.com/doc/refman/8.0/en/binary-log.html">5.4.4 The Binary Log</a></strong></p><p><strong>MySQL版本：MySQL 8.0</strong></p><h2 id="结论："><a href="#结论：" class="headerlink" title="结论："></a>结论：</h2><ul><li><strong>只有事务提交才会更新binlog</strong></li></ul><ul><li><strong>一个事务小于binlog cache size的时候会使用内存缓存，大于binlog cache size但是小于max binlog cache size会同时使用内存和临时文件（磁盘）作缓存，大于max binlog cache size会直接报错</strong></li></ul><hr><p>Binary logging is done immediately after a statement or transaction completes but before any locks are released or any commit is done. This ensures that the log is logged in commit order.</p><p>Within an uncommitted transaction, all updates (UPDATE, DELETE, or INSERT) that change transactional tables such as InnoDB tables are cached until a COMMIT statement is received by the server. At that point, mysqld writes the entire transaction to the binary log before the COMMIT is executed.</p><hr><p><strong><a href="https://dev.mysql.com/doc/refman/8.0/en/replication-options-binary-log.html#sysvar_binlog_cache_size">binlog cache size</a></strong></p><p>When a thread that handles the transaction starts, it allocates a buffer of binlog_cache_size to buffer statements. If a statement is bigger than this, the thread opens a temporary file to store the transaction. The temporary file is deleted when the thread ends.</p><p>The size of the memory buffer to hold changes to the binary log during a transaction. The value must be a multiple of 4096.</p><p>When binary logging is enabled on the server (with the log_bin system variable set to ON), a binary log cache is allocated for each client if the server supports any transactional storage engines. If the data for the transaction exceeds the space in the memory buffer, the excess data is stored in a temporary file. After each transaction is committed, the binary log cache is reset by clearing the memory buffer and truncating the temporary file if used.</p><p>If you often use large transactions, you can increase this cache size to get better performance by reducing or eliminating the need to write to temporary files. The Binlog_cache_use and Binlog_cache_disk_use status variables can be useful for tuning the size of this variable. See Section 5.4.4, “The Binary Log”.</p><p>binlog_cache_size sets the size for the transaction cache only; the size of the statement cache is governed by the binlog_stmt_cache_size system variable.</p><hr><p><strong><a href="https://dev.mysql.com/doc/refman/8.0/en/replication-options-binary-log.html#sysvar_max_binlog_cache_size">max binlog cache size</a></strong></p><p>The max_binlog_cache_size system variable (default 4GB, which is also the maximum) can be used to restrict the total size used to cache a multiple-statement transaction. If a transaction is larger than this many bytes, it fails and rolls back. The minimum value is 4096.</p><p>If a transaction requires more than this many bytes of memory, the server generates a Multi-statement transaction required more than ‘max_binlog_cache_size’ bytes of storage error. The minimum value is 4096. The maximum possible value is 16EiB (exbibytes). The maximum recommended value is 4GB; this is due to the fact that MySQL currently cannot work with binary log positions greater than 4GB. The value must be a multiple of 4096.</p><p>max_binlog_cache_size sets the size for the transaction cache only; the upper limit for the statement cache is governed by the max_binlog_stmt_cache_size system variable.</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>《Rust语言圣经》笔记（基础入门）</title>
    <link href="/2022/01/24/%E3%80%8ARust%E8%AF%AD%E8%A8%80%E5%9C%A3%E7%BB%8F%E3%80%8B%E7%AC%94%E8%AE%B0%EF%BC%88%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%EF%BC%89/"/>
    <url>/2022/01/24/%E3%80%8ARust%E8%AF%AD%E8%A8%80%E5%9C%A3%E7%BB%8F%E3%80%8B%E7%AC%94%E8%AE%B0%EF%BC%88%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%EF%BC%89/</url>
    
    <content type="html"><![CDATA[<h1 id="《Rust语言圣经》笔记（基础入门）"><a href="#《Rust语言圣经》笔记（基础入门）" class="headerlink" title="《Rust语言圣经》笔记（基础入门）"></a>《Rust语言圣经》笔记（基础入门）</h1><p>最近在学习<a href="https://github.com/sunface/rust-course">《Rust语言圣经》</a> ，并参与了贡献，希望大家多提意见，一起完善这个项目。</p><h2 id="usize、isize类型的引入"><a href="#usize、isize类型的引入" class="headerlink" title="usize、isize类型的引入"></a>usize、isize类型的引入</h2><p>isize 和 usize 类型取决于程序运行的计算机cpu类型：若cpu是32位的，则这两个类型是32位的，同理，若cpu是64位，那么它们则是64位。</p><h2 id="所有权的引入"><a href="#所有权的引入" class="headerlink" title="所有权的引入"></a>所有权的引入</h2><p>Rust之所以能万众瞩目，是因为其内存安全的特性。在以往，内存安全几乎都是通过GC来保证的，但是GC会带来性能、内存占用以及Stop the world等问题，在高性能场景和系统编程上是不可接受的，因此Rust采用了所有权系统。</p><p>所有的程序都必须和计算机内存打交道，如何从内存中申请空间来存放程序的运行内容，如何在不需要的时候释放这些空间，成了重中之重，也是所有编程语言设计的难点之一。在计算机语言不断演变过程中，出现了三种流派：</p><ul><li>垃圾回收机制(GC)，在程序运行时不断寻找不再使用的内存，典型代表：Java、Go</li><li>手动管理内存的分配和释放, 在程序中，通过函数调用的方式来申请和释放内存，典型代表：C、C++</li><li>通过所有权来管理内存，编译器在编译时会根据一系列规则进行检查</li></ul><p>其中Rust选择了第三种，最妙的是，这种检查只发生在编译期，因此对于程序运行期，不会有任何性能上的损失。</p><p>手动管理内存的分配和释放很可能由于程序员的疏忽导致异常，C语言中一段不安全的代码如下：</p><pre><code>int* foo() &#123;    int x = 100;     return &amp;x;&#125;// 变量x是整型，所以声明后会在栈上申请空间，退出函数后栈释放掉了，造成了悬浮指针。//（在栈上声明的变量离开作用域后都会自动释放）// 想要解决这个问题可以通过malloc在堆上申请空间</code></pre><h2 id="堆与栈的性能区别"><a href="#堆与栈的性能区别" class="headerlink" title="堆与栈的性能区别"></a>堆与栈的性能区别</h2><p>栈和堆是编程语言最核心的数据结构，但是在很多语言中，你并不需要深入了解栈与堆。 但对于Rust这样的系统编程语言，值是位于栈上还是堆上非常重要, 因为这会影响程序的行为和性能。</p><p>栈和堆的核心目标就是为程序在运行时提供可供使用的内存空间。</p><p>写入方面：入栈比在堆上分配内存要快，因为入栈时操作系统无需分配新的空间，只需要将新数据放入栈顶即可。相比之下，在堆上分配内存则需要更多的工作，这是因为操作系统必须首先找到一块足够存放数据的内存空间，接着做一些记录为下一次分配做准备。</p><p>读取方面：得益于CPU高速缓存，使得处理器可以减少对内存的访问，高速缓存和内存的访问速度差异在10倍以上！栈数据往往可以直接存储在CPU高速缓存中，而堆数据只能存储在内存中。访问堆上的数据比访问栈上的数据慢，因为必须先访问堆再通过堆上的指针来访问内存。</p><p>因此，处理器处理和分配在栈上数据会比在堆上的数据更加高效。</p><h2 id="所有权的规则"><a href="#所有权的规则" class="headerlink" title="所有权的规则"></a>所有权的规则</h2><p>某些语言中存在深拷贝和浅拷贝的概念，在Rust中也有类似的概念</p><p>存储在栈上的基本数据类型（如整型、浮点型、字符、布尔）是通过自动拷贝的方式来赋值的，因为存放在栈上的数据足够简单，而且拷贝非常非常快，只需要复制一个整数大小(i32，4个字节)的内存即可，相当于在栈上做了深拷贝。</p><p>存储在堆上的数据赋值与浅拷贝类似（如String），不同的是，赋值之后，之前的变量无效了，因此这个操作成为移动（move）。Rust中可以通过clone方法来完成深拷贝，但是使用频繁会降低程序性能。</p><h2 id="借用的规则"><a href="#借用的规则" class="headerlink" title="借用的规则"></a>借用的规则</h2><p>同一时刻，只能有一个可变引用或者任意多个不可变引用</p><h2 id="字符串"><a href="#字符串" class="headerlink" title="字符串"></a>字符串</h2><p>在对字符串使用切片语法时需要格外小心，切片的索引必须落在字符之间的边界位置，也就是UTF8字符的边界，例如中文在UT8中占用三个字节,下面的代码就会崩溃:</p><pre><code>#![allow(unused)]fn main() &#123; let s = &quot;中国人&quot;; let a = &amp;s[0..2]; println!(&quot;&#123;&#125;&quot;,a);&#125;</code></pre><p>因为这里只取s字符串的前两个字节，但是一个中文占用三个字节，因此没有落在边界处，也就是连中字都取不完整，此时程序会直接崩溃退出，如果改成&amp;a[0..3]，则可以正常通过编译. 因此，当需要对字符串做切片索引操作时，需要格外小心这一点。</p><p>str：str是“预分配文本(preallocated text)”的字符串，这个预分配文本存储在可执行程序的只读内存中。换句话说，这是装载我们程序的内存并且不依赖于在堆上分配的缓冲区。只可以读，不可以修改。</p><p>&amp;str：str切片，只是对str的一个引用（）。只可以读，不可以通过切片对str进行修改。</p><p>String：Rust会在栈上存储String对象。这个对象里包含以下三个信息: 一个指针指向一块分配在堆上的缓冲区，这也是数据真正存储的地方，数据的容量和长度。因此，String对象本身长度总是固定的三个字(word)。String之所以为String的一个原因在于它能够根据需要调整缓冲区的容量。例如，我们能够使用push_str()方法追加更多的文本，这种追加操作可能会引起缓冲区的增长。</p><h2 id="结构体"><a href="#结构体" class="headerlink" title="结构体"></a>结构体</h2><p>必须要将整个结构体都声明为可变的，才能修改其中的字段，Rust不允许单独将某个字段标记为可变。</p><p>把结构体中具有所有权的字段转移出去后，将无法再访问该字段，但是可以正常访问其它的字段。</p><h2 id="匹配守卫与-绑定"><a href="#匹配守卫与-绑定" class="headerlink" title="匹配守卫与@绑定"></a>匹配守卫与@绑定</h2><p>匹配守卫（match guard）是一个位于 <code>match</code> 分支模式之后的额外 <code>if</code> 条件，它能为分支提供更进一步的匹配条件，这个条件可以使用模式中创建的变量：</p><pre><code>let num = Some(4);match num &#123;    Some(x) if x &lt; 5 =&gt; println!(&quot;less than five: &#123;&#125;&quot;, x),    Some(x) =&gt; println!(&quot;&#123;&#125;&quot;, x),    None =&gt; (),&#125;</code></pre><p>这个例子会打印出 <code>less than five: 4</code>。当 <code>num</code> 与模式中第一个分支匹配时， <code>Some(4)</code> 可以与 <code>Some(x)</code>匹配，接着匹配守卫检查 <code>x</code> 值是否小于 <code>5</code>，因为 <code>4</code> 小于 <code>5</code>，所以第一个分支被选择。</p><p>相反如果 <code>num</code> 为 <code>Some(10)</code>，因为 10 不小于 5 ，所以第一个分支的匹配守卫为假。接着 Rust 会前往第二个分支，因为这里没有匹配守卫所以会匹配任何 <code>Some</code> 成员。</p><p>模式中无法提供类如<code>if x &lt; 5</code>的表达能力，我们可以通过匹配守卫的方式来实现。</p><p>也可以在匹配守卫中使用 <strong>或</strong> 运算符 <code>|</code> 来指定多个模式，<strong>同时匹配守卫的条件会作用于所有的模式</strong>。下面代码展示了匹配守卫与 <code>|</code> 的优先级。这个例子中看起来好像 <code>if y</code> 只作用于 <code>6</code>，但实际上匹配守卫 <code>if y</code> 作用于 <code>4</code>、<code>5</code> <strong>和</strong> <code>6</code> ，在满足<code>x</code>属于 <code>4 | 5 | 6</code> 后才会判断 <code>y</code> 是否为 <code>true</code>：</p><pre><code>let x = 4;let y = false;match x &#123;    4 | 5 | 6 if y =&gt; println!(&quot;yes&quot;),    _ =&gt; println!(&quot;no&quot;),&#125;</code></pre><p>这个匹配条件表明此分支只匹配 <code>x</code> 值为 <code>4</code>、<code>5</code> 或 <code>6</code> <strong>同时</strong> <code>y</code> 为 <code>true</code> 的情况。</p><p>虽然在第一个分支中，<code>x</code> 匹配了模式 <code>4</code>，但是对于匹配守卫 if y<code>来说，因为 </code>y<code>是</code>false<code>，因此该守卫条件的值永远是</code>false`，也意味着第一个分支永远无法被匹配。</p><p>下面的文字图解释了匹配守卫作用于多个模式时的优先级规则，第一张是正确的：</p><pre><code>(4 | 5 | 6) if y =&gt; ...</code></pre><p>而第二张图是错误的</p><pre><code>4 | 5 | (6 if y) =&gt; ...</code></pre><p>可以通过运行代码时的情况看出这一点：如果匹配守卫只作用于由 <code>|</code> 运算符指定的值列表的最后一个值，这个分支就会匹配且程序会打印出 <code>yes</code>。</p><p><code>@</code>(读作at)运算符允许为一个字段绑定另外一个变量。下面例子中，我们希望测试 <code>Message::Hello</code> 的 <code>id</code> 字段是否位于 <code>3..=7</code> 范围内，同时也希望能将其值绑定到 <code>id_variable</code> 变量中以便此分支中相关的代码可以使用它。我们可以将 <code>id_variable</code> 命名为 <code>id</code>，与字段同名，不过出于示例的目的这里选择了不同的名称。</p><pre><code>enum Message &#123;    Hello &#123; id: i32 &#125;,&#125;let msg = Message::Hello &#123; id: 5 &#125;;match msg &#123;    Message::Hello &#123; id: id_variable @ 3..=7 &#125; =&gt; &#123;        println!(&quot;Found an id in range: &#123;&#125;&quot;, id_variable)    &#125;,    Message::Hello &#123; id: 10..=12 &#125; =&gt; &#123;        println!(&quot;Found an id in another range&quot;)    &#125;,    Message::Hello &#123; id &#125; =&gt; &#123;        println!(&quot;Found some other id: &#123;&#125;&quot;, id)    &#125;,&#125;</code></pre><p>上例会打印出 <code>Found an id in range: 5</code>。通过在 <code>3..=7</code> 之前指定 <code>id_variable @</code>，我们捕获了任何匹配此范围的值并同时将该值绑定到变量<code>id_variable</code>上。</p><p>第二个分支只在模式中指定了一个范围，<code>id</code> 字段的值可以是 <code>10、11 或 12</code>，不过这个模式的代码并不知情也不能使用 <code>id</code> 字段中的值，因为没有将 <code>id</code> 值保存进一个变量。</p><p>最后一个分支指定了一个没有范围的变量，此时确实拥有可以用于分支代码的变量 <code>id</code>，因为这里使用了结构体字段简写语法。不过此分支中没有像头两个分支那样对 <code>id</code> 字段的值进行测试：任何值都会匹配此分支。</p><p>当既想要限定分支范围，又想要使用分支的变量时，就可以用<code>@</code>来绑定到一个新的变量上，实现想要的功能。</p><h2 id="关联类型"><a href="#关联类型" class="headerlink" title="关联类型"></a>关联类型</h2><p>关联类型是在特征定义的语句块中，申明一个自定义类型，这样就可以在特征的方法签名中使用该类型：</p><pre><code>pub trait Iterator &#123;    type Item;    fn next(&amp;mut self) -&gt; Option&lt;Self::Item&gt;;&#125;</code></pre><p>以上是标准库中的迭代器特征 <code>Iterator</code>，它有一个 <code>Item</code> 关联类型，用于替代遍历的值的类型。</p><p>同时，<code>next</code> 方法也返回了一个 <code>Item</code> 类型，不过使用 <code>Option</code> 枚举进行了包裹，假如迭代器中的值是 <code>i32</code> 类型，那么调用 <code>next</code> 方法就将获取一个 <code>Option&lt;i32&gt;</code> 的值。</p><p><code>Self</code> 用来指代当前的特征实例，那么 <code>Self::Item</code> 就用来指代特征实例中具体的 <code>Item</code> 类型：</p><pre><code>impl Iterator for Counter &#123;       type Item = u32;    fn next(&amp;mut self) -&gt; Option&lt;Self::Item&gt; &#123;    // --snip--    ｝｝</code></pre><p>在上述代码中，我们为 <code>Counter</code> 类型实现了 <code>Iterator</code> 特征，那么 <code>Self</code> 就是当前的 <code>Iterator</code> 特征对象， <code>Item</code> 就是 <code>u32</code> 类型。</p><p>这里也可以使用泛型，例如如下代码：</p><pre><code>pub trait Iterator&lt;Item&gt; &#123;    fn next(&amp;mut self) -&gt; Option&lt;Item&gt;;&#125;</code></pre><p>但是考虑到代码的可读性，当你使用了泛型后，你需要在所有地方都写 <code>Iterator&lt;Item&gt;</code>，而使用了关联类型，你只需要写 <code>Iterator</code>，当类型定义复杂时，这种写法可以极大的增加可读性：</p><pre><code>pub trait CacheableItem: Clone + Default + fmt::Debug + Decodable + Encodable &#123;  type Address: AsRef&lt;[u8]&gt; + Clone + fmt::Debug + Eq + Hash;  fn is_null(&amp;self) -&gt; bool;&#125;</code></pre><p>例如上面的代码， <code>Address</code> 的写法自然远比 <code>AsRef&lt;[u8]&gt; + Clone + fmt::Debug + Eq + Hash</code> 要简单的多，而且含义清晰。</p><p>再例如，如果使用泛型，你将得到以下的代码：</p><pre><code>trait Container&lt;A,B&gt; &#123;    fn contains(&amp;self,a: A,b: B) -&gt; bool;&#125;fn difference&lt;A,B,C&gt;(container: &amp;C) -&gt; i32  where C : Container&lt;A,B&gt; &#123;    ...&#125;</code></pre><p>可以看到，由于使用了泛型，导致函数头部也必须增加泛型的声明，而使用关联类型，将得到可读性好得多的代码：</p><pre><code>trait Container&#123;    type A;    type B;    fn contains(&amp;self, a: &amp;Self::A, b: &amp;Self::B) -&gt; bool;&#125;</code></pre><p>fn difference&lt;C: Container&gt;(container: &amp;C) {}</p><h2 id="impl-Trait-和-dyn-Trait"><a href="#impl-Trait-和-dyn-Trait" class="headerlink" title="impl Trait 和 dyn Trait"></a>impl Trait 和 dyn Trait</h2><p>impl Trait 和 dyn Trait 在 Rust 分别被称为静态分发和动态分发。</p><p>语法的角度：impl Trait会出现在两个位置：参数位置,返回值位置。</p><p>当代码涉及多态时, 需要某种机制决定实际调用类型，Rust 的 Trait 可以看作某些具有通过特性类型的集合, 静态分发, 正如静态类型语言的”静态”一词说明的, 在编译期就确定了具体调用类型。 Rust 编译器会通过单态化(Monomorphization) 将泛型函数展开。通过单态化,编译器消除了泛型,而且没有性能损耗,这也是 Rust 提倡的形式, 缺点是过多展开可能会导致编译生成的二级制文件体积过大,这时候可能需要重构代码。</p><p>静态分发虽然有很高的性能,但在文章开头其另一个缺点也有所体现,那就是无法让函数返回多种类型,因此 Rust 也支持通过 trait object （Box<dyn>）实现动态分发。既然 Trait 是具有某种特性的类型的集合,那我们可以把 Trait 也看作某种类型,但它是”抽象的”,就像 OOP 中的抽象类或基类,不能直接实例化。</p><p>Rust 的 trait object 使用了与 c++ 类似的 vtable 实现, trait object 含有1个指向实际类型的 data 指针,和一个指向实际类型实现 trait 函数的 vtable, 以此实现动态分发。更加详细的介绍可以参考：<a href="https://alschwalm.com/blog/static/2017/03/07/exploring-dynamic-dispatch-in-rust/">Exploring Dynamic Dispatch in Rust</a></p><p>参考：</p><p><a href="https://course.rs/basic/trait/trait.html">特征Trait</a></p><p><a href="https://course.rs/basic/trait/trait-object.html">特征对象</a></p><p><a href="https://zhuanlan.zhihu.com/p/257090324">Rust：impl Trait vs impl dyn Trait</a></p><p><a href="https://zhuanlan.zhihu.com/p/109990547">捋捋 Rust 中的 impl Trait 和 dyn Trait</a></p><h2 id="从Vector中读取函数"><a href="#从Vector中读取函数" class="headerlink" title="从Vector中读取函数"></a>从Vector中读取函数</h2><p>读取数组中的元素可以通过下标索引和.get两种方式获取，区别是前者会检查下标是否越界，需要对返回的 Option 做处理，而且会有略微的性能损耗，但是如果可以确保下标不会越界，那么可以直接用索引访问。</p><h2 id="哈希函数"><a href="#哈希函数" class="headerlink" title="哈希函数"></a>哈希函数</h2><p>目前，HashMap 使用的哈希函数是 SipHash，它的性能不是很高，但是安全性很高。SipHash 在中等大小的 Key 上，性能相当不错，但是对于小型的 Key (例如整数)或者大型 Key (例如字符串)来说，性能还是不够好。若你需要极致性能，可以考虑别的库的实现。</p><h2 id="Transmute"><a href="#Transmute" class="headerlink" title="Transmute"></a>Transmute</h2><p>mem::transmute&lt;T, U&gt; 将类型 T 直接转成类型 U，唯一的要求就是，这两个类型占用同样大小的字节数。转换后创建一个任意类型的实例会造成无法想象的混乱，而且根本无法预测。</p><h2 id="panic"><a href="#panic" class="headerlink" title="panic"></a>panic</h2><p>如果是 main 线程，则程序会终止，如果是其它子线程，该线程会终止，但是不会影响 main 线程。因此，尽量不要在 main 线程中做太多任务，将这些任务交由子线程去做，就算子线程 panic 也不会导致整个程序的结束。</p><p>当调用 panic! 宏时，它会：</p><ol><li><p>格式化 panic 信息，然后使用该信息作为参数，调用 std::panic::panic_any() 函数</p></li><li><p>panic_any 会检查应用是否使用了 panic hook，如果使用了，该 hook 函数就会被调用（hook是一个钩子函数，是外部代码设置的，用于在panic触发时，执行外部代码所需的功能）</p><pre><code> use std::panic; panic::set_hook(Box::new(|_| &#123;     println!(&quot;Custom panic hook&quot;); &#125;)); panic!(&quot;Normal panic&quot;);</code></pre></li></ol><h2 id="unwrap-和-expect"><a href="#unwrap-和-expect" class="headerlink" title="unwrap 和 expect"></a>unwrap 和 expect</h2><p>expect相比unwrap能提供更精确的错误信息。</p>]]></content>
    
    
    <categories>
      
      <category>Rust</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Rust</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Asynchronous Programming in Rust</title>
    <link href="/2022/01/05/Asynchronous%20Programming%20in%20Rust/"/>
    <url>/2022/01/05/Asynchronous%20Programming%20in%20Rust/</url>
    
    <content type="html"><![CDATA[<h1 id="Asynchronous-Programming-in-Rust"><a href="#Asynchronous-Programming-in-Rust" class="headerlink" title="Asynchronous Programming in Rust"></a>Asynchronous Programming in Rust</h1><hr><p><strong>记录对Rust异步编程的一些理解</strong></p><h3 id="关于Tokio-Runtime"><a href="#关于Tokio-Runtime" class="headerlink" title="关于Tokio Runtime"></a>关于Tokio Runtime</h3><blockquote><p>Tokio is able to concurrently run many tasks on a few threads by repeatedly swapping the currently running task on each thread. However, this kind of swapping can only happen at .await points, so code that spends a long time without reaching an .await will prevent other tasks from running. To combat this, Tokio provides two kinds of threads: Core threads and blocking threads. The core threads are where all asynchronous code runs, and Tokio will by default spawn one for each CPU core. The blocking threads are spawned on demand, can be used to run blocking code that would otherwise block other tasks from running and are kept alive when not used for a certain amount of time which can be configured with thread_keep_alive. Since it is not possible for Tokio to swap out blocking tasks, like it can do with asynchronous code, the upper limit on the number of blocking threads is very large. These limits can be configured on the Builder.</p></blockquote><p>Tokio 通过在每个线程上频繁换入换出当前正在运行的Task，达到能够在多个线程上同时运行多个Task的效果。但是，这种交换只能在代码执行到.await时触发，因此一个Task长时间未执行.await将阻止其他Task的运行（因为线程一直被当前执行的Task占用）。为了解决这个问题，Tokio 提供了两种线程：<strong>核心线程</strong>和<strong>阻塞线程</strong>。核心线程是所有异步代码运行的地方，默认情况下，Tokio 将为每个 CPU core生成一个。阻塞线程是按需产生的，可用于运行阻塞代码，否则会阻塞其他Task的运行，并且在一段时间不使用时保持活动状态，可以配置为thread_keep_alive. 由于 Tokio 不可能像处理异步代码那样交换阻塞任务，因此阻塞线程数的上限可以非常大，可以在通过Runtime builder来手动配置。</p><p>也就是说，Tokio Runtime在会存在两个线程池：<strong>阻塞线程池（Blocking threads）</strong>和<strong>异步线程池（Core threads）</strong></p><ul><li><strong>阻塞线程池</strong>可以用于运行同步代码，线程池默认上限为512，我们可以手动指定最大数量，它会随着程序的运行动态申请。</li><li><strong>异步线程池</strong>可以用于运行异步代码，线程池中默认的数量为CPU核心数，异步线程池中的线程占满后数量不会再增加。</li></ul><hr><h3 id="关于同步与异步互相调用"><a href="#关于同步与异步互相调用" class="headerlink" title="关于同步与异步互相调用"></a>关于同步与异步互相调用</h3><p>正常同步和异步的执行是这样的：</p><ul><li>在完全同步的代码中，执行逻辑比较简单，占用当前线程顺序执行即可，阻塞当前线程是可以理解的也是必须的。</li><li>在常规的异步代码中，遇到耗时会阻塞线程的操作可以通过调用.await，将其换出线程并换入其他Task，不会阻塞当前异步线程。</li></ul><p>Rust中普通fn方法为同步方法，执行过程中会持续占用当前线程；而async fn为异步方法，在执行过程中遇到.await时会被换出当前线程。</p><p>所以换个角度理解，<strong>一个方法是普通fn，那么就应当阻塞当前线程，而如果一个方法是async fn，就应该对外保证不会长时间阻塞当前线程</strong>，这也是我们在开发过程中应当遵守的原则。</p><p>我们的Tokio使用场景中，存在许多场景是比上面的情况要复杂的，有同步与异步混用的情况，即同步代码调用异步代码或是异步代码调用同步代码，开发过程中出现的一个问题是，异步调用了同步代码，同步代码阻塞了异步线程导致了异步Task无法得到线程去执行，所以说到底，这个问题产生的原因在于我们违背了这个原则：<strong>一个方法是普通fn，那么就应当阻塞当前线程，而如果一个方法是async fn，就应该对外保证不会长时间阻塞当前线程</strong>。</p><hr><h3 id="Spawn，Spawn-blocking，Block-in-place"><a href="#Spawn，Spawn-blocking，Block-in-place" class="headerlink" title="Spawn，Spawn blocking，Block in place"></a>Spawn，Spawn blocking，Block in place</h3><p>在编写同步与异步代码的过程中应当想办法满足上面的原则：</p><p><strong>同步调用异步（fn -&gt;async）</strong>：最外层函数为fn，所以要保证整个函数为同步的，可以使用block_on()的方式：</p><pre><code>pub fn block_on&lt;F: Future&gt;(&amp;self, future: F) -&gt; F::Output</code></pre><blockquote><p>Run a future to completion on the Tokio runtime. This is the runtime’s entry point.</p><p>This runs the given future on the current thread, blocking until it is complete, and yielding its resolved result. Any tasks or timers which the future spawns internally will be executed on the runtime.</p></blockquote><p>block会阻塞当前线程，直至运行完成，这样可以保证整个函数对外是同步的。</p><p><strong>异步调用同步（async-&gt;fn）</strong>：最外层函数为async，所以要保证整个函数为异步的，可以使用spawn_blocking()的方式：</p><pre><code>pub fn spawn_blocking&lt;F, R&gt;(f: F) -&gt; JoinHandle&lt;R&gt; </code></pre><blockquote><p>Runs the provided closure on a thread where blocking is acceptable.</p></blockquote><p>spawn blocking会使用阻塞线程池上的线程来运行同步函数，调用spawn blocking的函数会让出异步线程让其他Task运行。</p><p>关于block in place，曾向Tokio的作者请教过：<a href="https://github.com/tokio-rs/tokio/discussions/4003">about block in place()</a></p><p><img src="/img/post/block_in_place.png" alt="block in place"></p>]]></content>
    
    
    <categories>
      
      <category>Rust</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Rust</tag>
      
      <tag>Tokio</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Bitcask</title>
    <link href="/2021/12/30/Bitcask/"/>
    <url>/2021/12/30/Bitcask/</url>
    
    <content type="html"><![CDATA[<h1 id="Bitcask"><a href="#Bitcask" class="headerlink" title="Bitcask"></a>Bitcask</h1><h2 id="A-Log-Structured-Fast-KV-Store"><a href="#A-Log-Structured-Fast-KV-Store" class="headerlink" title="A Log-Structured Fast KV Store"></a>A Log-Structured Fast KV Store</h2><p>学习Bitcask的缘由是在Rust中文社区看到了一名高中生正在用Rust实现一个Key-Value数据库系统：Dorea，抱着学习的心态下载了这个项目研究了一下，这个数据库系统使用的存储方案是一个基于hash表结构和key-value的日志型存储模型，名为Bitcask。</p><p>Bitcask起源于一篇同名的数据库模型论文，这篇论文阅读起来没有什么障碍，读完很快就可以理解。豆瓣在2018年就已经基于Bitcask开发了适合于豆瓣使用场景的海量小文件存储系统BeansDB，并成功应用于应用于生产环境，类似的项目还有使用Go语言开发的RoseDB（未应用于生产环境）。</p><p>下面记录一下我对Bitcask的理解，后续会考虑将其应用到Dorea的开发中。</p><hr><p>论文地址：<a href="https://github.com/JesseAtSZ/Bibliography-Collection">Bitcask- A Log-Structured Hash Table for Fast KeyValue Data</a></p><hr><h3 id="日志型的数据文件"><a href="#日志型的数据文件" class="headerlink" title="日志型的数据文件"></a>日志型的数据文件</h3><p>所谓日志型，就是Append only，所有写操作只允许追加新的数据而不允许修改老的数据，就像我们的各种服务器日志一样。</p><p>在Bitcask模型中，数据只增不减地写入文件中，每个文件有一定的大小限制，当文件大小达到到相应的限制时，就会产生一个新的文件并在新的文件中继续进行追加，而老的文件将只读不写。在任意时刻，只有一个文件是可以写入的，Bitcask模型中将当前可以写入的文件称为为Active Data File，而其他的已经达到限制大小的文件，称为Old Data File。</p><p>文件中的数据结构非常简单，每一条数据的结构分别为Key，Value，Key Size，Value Size，Timestamp，Crc校验值，一条条这样格式的数据就组成了数据文件：</p><p><img src="/img/post/Bitcask_Datafiles.png" alt="Bitcask_Datafiles"></p><p>如果数据文件这样持续的存下去，是会无限膨胀的，为了解决个问题，Bitcask有一个定期的Merge操作，定期将所有Old Data File中的数据扫描一遍并生成新的Data File（没有包括Active Data File 是因为它还在不停写入），这里的Merge其实就是将同一个Key的多个数据只保留最新的一个。每次Merge后，新生成的数据文件就不再有冗余数据了。</p><h3 id="基于Hash-Table的索引数据"><a href="#基于Hash-Table的索引数据" class="headerlink" title="基于Hash Table的索引数据"></a>基于Hash Table的索引数据</h3><p>上面讲到的是数据文件，日志类型的数据文件会让我们的写入操作非常快，日志型的优势之一是将磁盘当作磁带，顺序读写的效率非常高，但是如果在这样的日志型数据上使用Key值进行顺序查找，是一件非常低效的事情，所以需要使用一些方法来提高查找效率。</p><p>在Bitcask模型中，使用了一个基于Hash Table的索引数据结构，除了存储在磁盘上的数据文件，还有另外一块数据，那就是存储在内存中的Hash Table，Hash Table的作用是通过Key值快速的定位到Value的位置。Hash Table的结构大致如下图所示：</p><p><img src="/img/post/Bitcask_KeyDir.png" alt="Bitcask_Datafiles"></p><p>Hash Table对应的这个结构中包括了三个用于定位数据Value的信息，分别是文件Id号(FILEID)，Value值在文件中的位置（VPOS），Value值的大小（VSZ），于是我们通过读取FILEID对应文件的VPOS开始的VSZ个字节，就可以得到我们需要的Value值。</p><h3 id="使用Hint-File对索引进行持久化"><a href="#使用Hint-File对索引进行持久化" class="headerlink" title="使用Hint File对索引进行持久化"></a>使用Hint File对索引进行持久化</h3><p>我们称其为索引的Hash Table，是存储在内存中的，Bitcask模型中并不保证在断电或重启后的Hash Table中的索引数据不丢失。</p><p>因此，我们每次启动时需要整个扫描一遍我们的数据文件，重建Hash Table索引，如果数据文件很大，这个重建的过程将非常耗时。因此Bitcask模型中包含了一个称作Hint File的部分，目的在于提高重建Hash Table索引的速度。</p><p>上面讲到在Old Data File进行merge操作时，会产生新的Data File，而Bitcask模型实际还建议同时生成一个Hint File，这个Hint File中每一项的数据结构，与Data file中的数据结构非常相似，不同的是他并不存储具体的Value值，而是存储Value的位置（像在Hash Table中的一样）,Hint File包含Key、Key Size、Value Size、Value Position、Timestamp。</p><p>这样，在重建Hash Table时，就不需要再扫描所有Data File文件，而只需要将Hint File中的数据一行行读取即可，这样就可以大大提高重启数据库的速度。</p><h3 id="更多资料"><a href="#更多资料" class="headerlink" title="更多资料"></a>更多资料</h3><p><a href="https://arpitbhayani.me/blogs/bitcask">Bitcask - A Log-Structured Fast KV Store</a></p><p><a href="https://dorea.mrxzx.info/">Dorea Database</a></p>]]></content>
    
    
    <categories>
      
      <category>Database</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Database</tag>
      
      <tag>Bitcask</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
