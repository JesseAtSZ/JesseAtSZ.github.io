<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>MySQL BinLog 更新</title>
    <link href="/2022/03/15/MySQL-BinLog-%E6%9B%B4%E6%96%B0/"/>
    <url>/2022/03/15/MySQL-BinLog-%E6%9B%B4%E6%96%B0/</url>
    
    <content type="html"><![CDATA[<p><strong>参考资料：<a href="https://dev.mysql.com/doc/refman/8.0/en/binary-log.html">5.4.4 The Binary Log</a></strong></p><p><strong>MySQL版本：MySQL 8.0</strong></p><h2 id="结论："><a href="#结论：" class="headerlink" title="结论："></a>结论：</h2><ul><li><strong>只有事务提交才会更新binlog</strong></li></ul><ul><li><strong>一个事务小于binlog cache size的时候会使用内存缓存，大于binlog cache size但是小于max binlog cache size会同时使用内存和临时文件（磁盘）作缓存，大于max binlog cache size会直接报错</strong></li></ul><hr><p>Binary logging is done immediately after a statement or transaction completes but before any locks are released or any commit is done. This ensures that the log is logged in commit order.</p><p>Within an uncommitted transaction, all updates (UPDATE, DELETE, or INSERT) that change transactional tables such as InnoDB tables are cached until a COMMIT statement is received by the server. At that point, mysqld writes the entire transaction to the binary log before the COMMIT is executed.</p><hr><p><strong><a href="https://dev.mysql.com/doc/refman/8.0/en/replication-options-binary-log.html#sysvar_binlog_cache_size">binlog cache size</a></strong></p><p>When a thread that handles the transaction starts, it allocates a buffer of binlog_cache_size to buffer statements. If a statement is bigger than this, the thread opens a temporary file to store the transaction. The temporary file is deleted when the thread ends.</p><p>The size of the memory buffer to hold changes to the binary log during a transaction. The value must be a multiple of 4096.</p><p>When binary logging is enabled on the server (with the log_bin system variable set to ON), a binary log cache is allocated for each client if the server supports any transactional storage engines. If the data for the transaction exceeds the space in the memory buffer, the excess data is stored in a temporary file. After each transaction is committed, the binary log cache is reset by clearing the memory buffer and truncating the temporary file if used.</p><p>If you often use large transactions, you can increase this cache size to get better performance by reducing or eliminating the need to write to temporary files. The Binlog_cache_use and Binlog_cache_disk_use status variables can be useful for tuning the size of this variable. See Section 5.4.4, “The Binary Log”.</p><p>binlog_cache_size sets the size for the transaction cache only; the size of the statement cache is governed by the binlog_stmt_cache_size system variable.</p><hr><p><strong><a href="https://dev.mysql.com/doc/refman/8.0/en/replication-options-binary-log.html#sysvar_max_binlog_cache_size">max binlog cache size</a></strong></p><p>The max_binlog_cache_size system variable (default 4GB, which is also the maximum) can be used to restrict the total size used to cache a multiple-statement transaction. If a transaction is larger than this many bytes, it fails and rolls back. The minimum value is 4096.</p><p>If a transaction requires more than this many bytes of memory, the server generates a Multi-statement transaction required more than ‘max_binlog_cache_size’ bytes of storage error. The minimum value is 4096. The maximum possible value is 16EiB (exbibytes). The maximum recommended value is 4GB; this is due to the fact that MySQL currently cannot work with binary log positions greater than 4GB. The value must be a multiple of 4096.</p><p>max_binlog_cache_size sets the size for the transaction cache only; the upper limit for the statement cache is governed by the max_binlog_stmt_cache_size system variable.</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>《Rust语言圣经》笔记（基础入门）</title>
    <link href="/2022/01/24/%E3%80%8ARust%E8%AF%AD%E8%A8%80%E5%9C%A3%E7%BB%8F%E3%80%8B%E7%AC%94%E8%AE%B0%EF%BC%88%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%EF%BC%89/"/>
    <url>/2022/01/24/%E3%80%8ARust%E8%AF%AD%E8%A8%80%E5%9C%A3%E7%BB%8F%E3%80%8B%E7%AC%94%E8%AE%B0%EF%BC%88%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%EF%BC%89/</url>
    
    <content type="html"><![CDATA[<h1 id="《Rust语言圣经》笔记（基础入门）"><a href="#《Rust语言圣经》笔记（基础入门）" class="headerlink" title="《Rust语言圣经》笔记（基础入门）"></a>《Rust语言圣经》笔记（基础入门）</h1><p>最近在学习<a href="https://github.com/sunface/rust-course">《Rust语言圣经》</a> ，并参与了贡献（一不小心成了二作），希望大家多提意见，一起完善这个项目。</p><h2 id="usize、isize类型的引入"><a href="#usize、isize类型的引入" class="headerlink" title="usize、isize类型的引入"></a>usize、isize类型的引入</h2><p>isize 和 usize 类型取决于程序运行的计算机cpu类型：若cpu是32位的，则这两个类型是32位的，同理，若cpu是64位，那么它们则是64位。</p><h2 id="所有权的引入"><a href="#所有权的引入" class="headerlink" title="所有权的引入"></a>所有权的引入</h2><p>Rust之所以能万众瞩目，是因为其内存安全的特性。在以往，内存安全几乎都是通过GC来保证的，但是GC会带来性能、内存占用以及Stop the world等问题，在高性能场景和系统编程上是不可接受的，因此Rust采用了所有权系统。</p><p>所有的程序都必须和计算机内存打交道，如何从内存中申请空间来存放程序的运行内容，如何在不需要的时候释放这些空间，成了重中之重，也是所有编程语言设计的难点之一。在计算机语言不断演变过程中，出现了三种流派：</p><ul><li>垃圾回收机制(GC)，在程序运行时不断寻找不再使用的内存，典型代表：Java、Go</li><li>手动管理内存的分配和释放, 在程序中，通过函数调用的方式来申请和释放内存，典型代表：C、C++</li><li>通过所有权来管理内存，编译器在编译时会根据一系列规则进行检查</li></ul><p>其中Rust选择了第三种，最妙的是，这种检查只发生在编译期，因此对于程序运行期，不会有任何性能上的损失。</p><p>手动管理内存的分配和释放很可能由于程序员的疏忽导致异常，C语言中一段不安全的代码如下：</p><pre><code>int* foo() &#123;    int x = 100;     return &amp;x;&#125;// 变量x是整型，所以声明后会在栈上申请空间，退出函数后栈释放掉了，造成了悬浮指针。//（在栈上声明的变量离开作用域后都会自动释放）// 想要解决这个问题可以通过malloc在堆上申请空间</code></pre><h2 id="堆与栈的性能区别"><a href="#堆与栈的性能区别" class="headerlink" title="堆与栈的性能区别"></a>堆与栈的性能区别</h2><p>栈和堆是编程语言最核心的数据结构，但是在很多语言中，你并不需要深入了解栈与堆。 但对于Rust这样的系统编程语言，值是位于栈上还是堆上非常重要, 因为这会影响程序的行为和性能。</p><p>栈和堆的核心目标就是为程序在运行时提供可供使用的内存空间。</p><p>写入方面：入栈比在堆上分配内存要快，因为入栈时操作系统无需分配新的空间，只需要将新数据放入栈顶即可。相比之下，在堆上分配内存则需要更多的工作，这是因为操作系统必须首先找到一块足够存放数据的内存空间，接着做一些记录为下一次分配做准备。</p><p>读取方面：得益于CPU高速缓存，使得处理器可以减少对内存的访问，高速缓存和内存的访问速度差异在10倍以上！栈数据往往可以直接存储在CPU高速缓存中，而堆数据只能存储在内存中。访问堆上的数据比访问栈上的数据慢，因为必须先访问堆再通过堆上的指针来访问内存。</p><p>因此，处理器处理和分配在栈上数据会比在堆上的数据更加高效。</p><h2 id="所有权的规则"><a href="#所有权的规则" class="headerlink" title="所有权的规则"></a>所有权的规则</h2><p>某些语言中存在深拷贝和浅拷贝的概念，在Rust中也有类似的概念</p><p>存储在栈上的基本数据类型（如整型、浮点型、字符、布尔）是通过自动拷贝的方式来赋值的，因为存放在栈上的数据足够简单，而且拷贝非常非常快，只需要复制一个整数大小(i32，4个字节)的内存即可，相当于在栈上做了深拷贝。</p><p>存储在堆上的数据赋值与浅拷贝类似（如String），不同的是，赋值之后，之前的变量无效了，因此这个操作成为移动（move）。Rust中可以通过clone方法来完成深拷贝，但是使用频繁会降低程序性能。</p><h2 id="借用的规则"><a href="#借用的规则" class="headerlink" title="借用的规则"></a>借用的规则</h2><p>同一时刻，只能有一个可变引用或者任意多个不可变引用</p><h2 id="字符串"><a href="#字符串" class="headerlink" title="字符串"></a>字符串</h2><p>在对字符串使用切片语法时需要格外小心，切片的索引必须落在字符之间的边界位置，也就是UTF8字符的边界，例如中文在UT8中占用三个字节,下面的代码就会崩溃:</p><pre><code>#![allow(unused)]fn main() &#123; let s = &quot;中国人&quot;; let a = &amp;s[0..2]; println!(&quot;&#123;&#125;&quot;,a);&#125;</code></pre><p>因为这里只取s字符串的前两个字节，但是一个中文占用三个字节，因此没有落在边界处，也就是连中字都取不完整，此时程序会直接崩溃退出，如果改成&amp;a[0..3]，则可以正常通过编译. 因此，当需要对字符串做切片索引操作时，需要格外小心这一点。</p><p>str：str是“预分配文本(preallocated text)”的字符串，这个预分配文本存储在可执行程序的只读内存中。换句话说，这是装载我们程序的内存并且不依赖于在堆上分配的缓冲区。只可以读，不可以修改。</p><p>&amp;str：str切片，只是对str的一个引用（）。只可以读，不可以通过切片对str进行修改。</p><p>String：Rust会在栈上存储String对象。这个对象里包含以下三个信息: 一个指针指向一块分配在堆上的缓冲区，这也是数据真正存储的地方，数据的容量和长度。因此，String对象本身长度总是固定的三个字(word)。String之所以为String的一个原因在于它能够根据需要调整缓冲区的容量。例如，我们能够使用push_str()方法追加更多的文本，这种追加操作可能会引起缓冲区的增长。</p><h2 id="结构体"><a href="#结构体" class="headerlink" title="结构体"></a>结构体</h2><p>必须要将整个结构体都声明为可变的，才能修改其中的字段，Rust不允许单独将某个字段标记为可变。</p><p>把结构体中具有所有权的字段转移出去后，将无法再访问该字段，但是可以正常访问其它的字段。</p><h2 id="匹配守卫与-绑定"><a href="#匹配守卫与-绑定" class="headerlink" title="匹配守卫与@绑定"></a>匹配守卫与@绑定</h2><p>匹配守卫（match guard）是一个位于 <code>match</code> 分支模式之后的额外 <code>if</code> 条件，它能为分支提供更进一步的匹配条件，这个条件可以使用模式中创建的变量：</p><pre><code>let num = Some(4);match num &#123;    Some(x) if x &lt; 5 =&gt; println!(&quot;less than five: &#123;&#125;&quot;, x),    Some(x) =&gt; println!(&quot;&#123;&#125;&quot;, x),    None =&gt; (),&#125;</code></pre><p>这个例子会打印出 <code>less than five: 4</code>。当 <code>num</code> 与模式中第一个分支匹配时， <code>Some(4)</code> 可以与 <code>Some(x)</code>匹配，接着匹配守卫检查 <code>x</code> 值是否小于 <code>5</code>，因为 <code>4</code> 小于 <code>5</code>，所以第一个分支被选择。</p><p>相反如果 <code>num</code> 为 <code>Some(10)</code>，因为 10 不小于 5 ，所以第一个分支的匹配守卫为假。接着 Rust 会前往第二个分支，因为这里没有匹配守卫所以会匹配任何 <code>Some</code> 成员。</p><p>模式中无法提供类如<code>if x &lt; 5</code>的表达能力，我们可以通过匹配守卫的方式来实现。</p><p>也可以在匹配守卫中使用 <strong>或</strong> 运算符 <code>|</code> 来指定多个模式，<strong>同时匹配守卫的条件会作用于所有的模式</strong>。下面代码展示了匹配守卫与 <code>|</code> 的优先级。这个例子中看起来好像 <code>if y</code> 只作用于 <code>6</code>，但实际上匹配守卫 <code>if y</code> 作用于 <code>4</code>、<code>5</code> <strong>和</strong> <code>6</code> ，在满足<code>x</code>属于 <code>4 | 5 | 6</code> 后才会判断 <code>y</code> 是否为 <code>true</code>：</p><pre><code>let x = 4;let y = false;match x &#123;    4 | 5 | 6 if y =&gt; println!(&quot;yes&quot;),    _ =&gt; println!(&quot;no&quot;),&#125;</code></pre><p>这个匹配条件表明此分支只匹配 <code>x</code> 值为 <code>4</code>、<code>5</code> 或 <code>6</code> <strong>同时</strong> <code>y</code> 为 <code>true</code> 的情况。</p><p>虽然在第一个分支中，<code>x</code> 匹配了模式 <code>4</code>，但是对于匹配守卫 if y<code>来说，因为 </code>y<code>是</code>false<code>，因此该守卫条件的值永远是</code>false`，也意味着第一个分支永远无法被匹配。</p><p>下面的文字图解释了匹配守卫作用于多个模式时的优先级规则，第一张是正确的：</p><pre><code>(4 | 5 | 6) if y =&gt; ...</code></pre><p>而第二张图是错误的</p><pre><code>4 | 5 | (6 if y) =&gt; ...</code></pre><p>可以通过运行代码时的情况看出这一点：如果匹配守卫只作用于由 <code>|</code> 运算符指定的值列表的最后一个值，这个分支就会匹配且程序会打印出 <code>yes</code>。</p><p><code>@</code>(读作at)运算符允许为一个字段绑定另外一个变量。下面例子中，我们希望测试 <code>Message::Hello</code> 的 <code>id</code> 字段是否位于 <code>3..=7</code> 范围内，同时也希望能将其值绑定到 <code>id_variable</code> 变量中以便此分支中相关的代码可以使用它。我们可以将 <code>id_variable</code> 命名为 <code>id</code>，与字段同名，不过出于示例的目的这里选择了不同的名称。</p><pre><code>enum Message &#123;    Hello &#123; id: i32 &#125;,&#125;let msg = Message::Hello &#123; id: 5 &#125;;match msg &#123;    Message::Hello &#123; id: id_variable @ 3..=7 &#125; =&gt; &#123;        println!(&quot;Found an id in range: &#123;&#125;&quot;, id_variable)    &#125;,    Message::Hello &#123; id: 10..=12 &#125; =&gt; &#123;        println!(&quot;Found an id in another range&quot;)    &#125;,    Message::Hello &#123; id &#125; =&gt; &#123;        println!(&quot;Found some other id: &#123;&#125;&quot;, id)    &#125;,&#125;</code></pre><p>上例会打印出 <code>Found an id in range: 5</code>。通过在 <code>3..=7</code> 之前指定 <code>id_variable @</code>，我们捕获了任何匹配此范围的值并同时将该值绑定到变量<code>id_variable</code>上。</p><p>第二个分支只在模式中指定了一个范围，<code>id</code> 字段的值可以是 <code>10、11 或 12</code>，不过这个模式的代码并不知情也不能使用 <code>id</code> 字段中的值，因为没有将 <code>id</code> 值保存进一个变量。</p><p>最后一个分支指定了一个没有范围的变量，此时确实拥有可以用于分支代码的变量 <code>id</code>，因为这里使用了结构体字段简写语法。不过此分支中没有像头两个分支那样对 <code>id</code> 字段的值进行测试：任何值都会匹配此分支。</p><p>当既想要限定分支范围，又想要使用分支的变量时，就可以用<code>@</code>来绑定到一个新的变量上，实现想要的功能。</p><h2 id="关联类型"><a href="#关联类型" class="headerlink" title="关联类型"></a>关联类型</h2><p>关联类型是在特征定义的语句块中，申明一个自定义类型，这样就可以在特征的方法签名中使用该类型：</p><pre><code>pub trait Iterator &#123;    type Item;    fn next(&amp;mut self) -&gt; Option&lt;Self::Item&gt;;&#125;</code></pre><p>以上是标准库中的迭代器特征 <code>Iterator</code>，它有一个 <code>Item</code> 关联类型，用于替代遍历的值的类型。</p><p>同时，<code>next</code> 方法也返回了一个 <code>Item</code> 类型，不过使用 <code>Option</code> 枚举进行了包裹，假如迭代器中的值是 <code>i32</code> 类型，那么调用 <code>next</code> 方法就将获取一个 <code>Option&lt;i32&gt;</code> 的值。</p><p><code>Self</code> 用来指代当前的特征实例，那么 <code>Self::Item</code> 就用来指代特征实例中具体的 <code>Item</code> 类型：</p><pre><code>impl Iterator for Counter &#123;       type Item = u32;    fn next(&amp;mut self) -&gt; Option&lt;Self::Item&gt; &#123;    // --snip--    ｝｝</code></pre><p>在上述代码中，我们为 <code>Counter</code> 类型实现了 <code>Iterator</code> 特征，那么 <code>Self</code> 就是当前的 <code>Iterator</code> 特征对象， <code>Item</code> 就是 <code>u32</code> 类型。</p><p>这里也可以使用泛型，例如如下代码：</p><pre><code>pub trait Iterator&lt;Item&gt; &#123;    fn next(&amp;mut self) -&gt; Option&lt;Item&gt;;&#125;</code></pre><p>但是考虑到代码的可读性，当你使用了泛型后，你需要在所有地方都写 <code>Iterator&lt;Item&gt;</code>，而使用了关联类型，你只需要写 <code>Iterator</code>，当类型定义复杂时，这种写法可以极大的增加可读性：</p><pre><code>pub trait CacheableItem: Clone + Default + fmt::Debug + Decodable + Encodable &#123;  type Address: AsRef&lt;[u8]&gt; + Clone + fmt::Debug + Eq + Hash;  fn is_null(&amp;self) -&gt; bool;&#125;</code></pre><p>例如上面的代码， <code>Address</code> 的写法自然远比 <code>AsRef&lt;[u8]&gt; + Clone + fmt::Debug + Eq + Hash</code> 要简单的多，而且含义清晰。</p><p>再例如，如果使用泛型，你将得到以下的代码：</p><pre><code>trait Container&lt;A,B&gt; &#123;    fn contains(&amp;self,a: A,b: B) -&gt; bool;&#125;fn difference&lt;A,B,C&gt;(container: &amp;C) -&gt; i32  where C : Container&lt;A,B&gt; &#123;    ...&#125;</code></pre><p>可以看到，由于使用了泛型，导致函数头部也必须增加泛型的声明，而使用关联类型，将得到可读性好得多的代码：</p><pre><code>trait Container&#123;    type A;    type B;    fn contains(&amp;self, a: &amp;Self::A, b: &amp;Self::B) -&gt; bool;&#125;</code></pre><p>fn difference&lt;C: Container&gt;(container: &amp;C) {}</p><h2 id="impl-Trait-和-dyn-Trait"><a href="#impl-Trait-和-dyn-Trait" class="headerlink" title="impl Trait 和 dyn Trait"></a>impl Trait 和 dyn Trait</h2><p>impl Trait 和 dyn Trait 在 Rust 分别被称为静态分发和动态分发。</p><p>语法的角度：impl Trait会出现在两个位置：参数位置,返回值位置。</p><p>当代码涉及多态时, 需要某种机制决定实际调用类型，Rust 的 Trait 可以看作某些具有通过特性类型的集合, 静态分发, 正如静态类型语言的”静态”一词说明的, 在编译期就确定了具体调用类型。 Rust 编译器会通过单态化(Monomorphization) 将泛型函数展开。通过单态化,编译器消除了泛型,而且没有性能损耗,这也是 Rust 提倡的形式, 缺点是过多展开可能会导致编译生成的二级制文件体积过大,这时候可能需要重构代码。</p><p>静态分发虽然有很高的性能,但在文章开头其另一个缺点也有所体现,那就是无法让函数返回多种类型,因此 Rust 也支持通过 trait object （Box<dyn>）实现动态分发。既然 Trait 是具有某种特性的类型的集合,那我们可以把 Trait 也看作某种类型,但它是”抽象的”,就像 OOP 中的抽象类或基类,不能直接实例化。</p><p>Rust 的 trait object 使用了与 c++ 类似的 vtable 实现, trait object 含有1个指向实际类型的 data 指针,和一个指向实际类型实现 trait 函数的 vtable, 以此实现动态分发。更加详细的介绍可以参考：<a href="https://alschwalm.com/blog/static/2017/03/07/exploring-dynamic-dispatch-in-rust/">Exploring Dynamic Dispatch in Rust</a></p><p>参考：</p><p><a href="https://course.rs/basic/trait/trait.html">特征Trait</a></p><p><a href="https://course.rs/basic/trait/trait-object.html">特征对象</a></p><p><a href="https://zhuanlan.zhihu.com/p/257090324">Rust：impl Trait vs impl dyn Trait</a></p><p><a href="https://zhuanlan.zhihu.com/p/109990547">捋捋 Rust 中的 impl Trait 和 dyn Trait</a></p><h2 id="从Vector中读取函数"><a href="#从Vector中读取函数" class="headerlink" title="从Vector中读取函数"></a>从Vector中读取函数</h2><p>读取数组中的元素可以通过下标索引和.get两种方式获取，区别是前者会检查下标是否越界，需要对返回的 Option 做处理，而且会有略微的性能损耗，但是如果可以确保下标不会越界，那么可以直接用索引访问。</p><h2 id="哈希函数"><a href="#哈希函数" class="headerlink" title="哈希函数"></a>哈希函数</h2><p>目前，HashMap 使用的哈希函数是 SipHash，它的性能不是很高，但是安全性很高。SipHash 在中等大小的 Key 上，性能相当不错，但是对于小型的 Key (例如整数)或者大型 Key (例如字符串)来说，性能还是不够好。若你需要极致性能，可以考虑别的库的实现。</p><h2 id="Transmute"><a href="#Transmute" class="headerlink" title="Transmute"></a>Transmute</h2><p>mem::transmute&lt;T, U&gt; 将类型 T 直接转成类型 U，唯一的要求就是，这两个类型占用同样大小的字节数。转换后创建一个任意类型的实例会造成无法想象的混乱，而且根本无法预测。</p><h2 id="panic"><a href="#panic" class="headerlink" title="panic"></a>panic</h2><p>如果是 main 线程，则程序会终止，如果是其它子线程，该线程会终止，但是不会影响 main 线程。因此，尽量不要在 main 线程中做太多任务，将这些任务交由子线程去做，就算子线程 panic 也不会导致整个程序的结束。</p><p>当调用 panic! 宏时，它会：</p><ol><li><p>格式化 panic 信息，然后使用该信息作为参数，调用 std::panic::panic_any() 函数</p></li><li><p>panic_any 会检查应用是否使用了 panic hook，如果使用了，该 hook 函数就会被调用（hook是一个钩子函数，是外部代码设置的，用于在panic触发时，执行外部代码所需的功能）</p><pre><code> use std::panic; panic::set_hook(Box::new(|_| &#123;     println!(&quot;Custom panic hook&quot;); &#125;)); panic!(&quot;Normal panic&quot;);</code></pre></li></ol><h2 id="unwrap-和-expect"><a href="#unwrap-和-expect" class="headerlink" title="unwrap 和 expect"></a>unwrap 和 expect</h2><p>expect相比unwrap能提供更精确的错误信息。</p>]]></content>
    
    
    <categories>
      
      <category>Rust</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Rust</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Asynchronous Programming in Rust</title>
    <link href="/2022/01/05/Asynchronous%20Programming%20in%20Rust/"/>
    <url>/2022/01/05/Asynchronous%20Programming%20in%20Rust/</url>
    
    <content type="html"><![CDATA[<h1 id="Asynchronous-Programming-in-Rust"><a href="#Asynchronous-Programming-in-Rust" class="headerlink" title="Asynchronous Programming in Rust"></a>Asynchronous Programming in Rust</h1><hr><p><strong>记录对Rust异步编程的一些理解</strong></p><h3 id="关于Tokio-Runtime"><a href="#关于Tokio-Runtime" class="headerlink" title="关于Tokio Runtime"></a>关于Tokio Runtime</h3><blockquote><p>Tokio is able to concurrently run many tasks on a few threads by repeatedly swapping the currently running task on each thread. However, this kind of swapping can only happen at .await points, so code that spends a long time without reaching an .await will prevent other tasks from running. To combat this, Tokio provides two kinds of threads: Core threads and blocking threads. The core threads are where all asynchronous code runs, and Tokio will by default spawn one for each CPU core. The blocking threads are spawned on demand, can be used to run blocking code that would otherwise block other tasks from running and are kept alive when not used for a certain amount of time which can be configured with thread_keep_alive. Since it is not possible for Tokio to swap out blocking tasks, like it can do with asynchronous code, the upper limit on the number of blocking threads is very large. These limits can be configured on the Builder.</p></blockquote><p>Tokio 通过在每个线程上频繁换入换出当前正在运行的Task，达到能够在多个线程上同时运行多个Task的效果。但是，这种交换只能在代码执行到.await时触发，因此一个Task长时间未执行.await将阻止其他Task的运行（因为线程一直被当前执行的Task占用）。为了解决这个问题，Tokio 提供了两种线程：<strong>核心线程</strong>和<strong>阻塞线程</strong>。核心线程是所有异步代码运行的地方，默认情况下，Tokio 将为每个 CPU core生成一个。阻塞线程是按需产生的，可用于运行阻塞代码，否则会阻塞其他Task的运行，并且在一段时间不使用时保持活动状态，可以配置为thread_keep_alive. 由于 Tokio 不可能像处理异步代码那样交换阻塞任务，因此阻塞线程数的上限可以非常大，可以在通过Runtime builder来手动配置。</p><p>也就是说，Tokio Runtime在会存在两个线程池：<strong>阻塞线程池（Blocking threads）</strong>和<strong>异步线程池（Core threads）</strong></p><ul><li><strong>阻塞线程池</strong>可以用于运行同步代码，线程池默认上限为512，我们可以手动指定最大数量，它会随着程序的运行动态申请。</li><li><strong>异步线程池</strong>可以用于运行异步代码，线程池中默认的数量为CPU核心数，异步线程池中的线程占满后数量不会再增加。</li></ul><hr><h3 id="关于同步与异步互相调用"><a href="#关于同步与异步互相调用" class="headerlink" title="关于同步与异步互相调用"></a>关于同步与异步互相调用</h3><p>正常同步和异步的执行是这样的：</p><ul><li>在完全同步的代码中，执行逻辑比较简单，占用当前线程顺序执行即可，阻塞当前线程是可以理解的也是必须的。</li><li>在常规的异步代码中，遇到耗时会阻塞线程的操作可以通过调用.await，将其换出线程并换入其他Task，不会阻塞当前异步线程。</li></ul><p>Rust中普通fn方法为同步方法，执行过程中会持续占用当前线程；而async fn为异步方法，在执行过程中遇到.await时会被换出当前线程。</p><p>所以换个角度理解，<strong>一个方法是普通fn，那么就应当阻塞当前线程，而如果一个方法是async fn，就应该对外保证不会长时间阻塞当前线程</strong>，这也是我们在开发过程中应当遵守的原则。</p><p>我们的Tokio使用场景中，存在许多场景是比上面的情况要复杂的，有同步与异步混用的情况，即同步代码调用异步代码或是异步代码调用同步代码，开发过程中出现的一个问题是，异步调用了同步代码，同步代码阻塞了异步线程导致了异步Task无法得到线程去执行，所以说到底，这个问题产生的原因在于我们违背了这个原则：<strong>一个方法是普通fn，那么就应当阻塞当前线程，而如果一个方法是async fn，就应该对外保证不会长时间阻塞当前线程</strong>。</p><hr><h3 id="Spawn，Spawn-blocking，Block-in-place"><a href="#Spawn，Spawn-blocking，Block-in-place" class="headerlink" title="Spawn，Spawn blocking，Block in place"></a>Spawn，Spawn blocking，Block in place</h3><p>在编写同步与异步代码的过程中应当想办法满足上面的原则：</p><p><strong>同步调用异步（fn -&gt;async）</strong>：最外层函数为fn，所以要保证整个函数为同步的，可以使用block_on()的方式：</p><pre><code>pub fn block_on&lt;F: Future&gt;(&amp;self, future: F) -&gt; F::Output</code></pre><blockquote><p>Run a future to completion on the Tokio runtime. This is the runtime’s entry point.</p><p>This runs the given future on the current thread, blocking until it is complete, and yielding its resolved result. Any tasks or timers which the future spawns internally will be executed on the runtime.</p></blockquote><p>block会阻塞当前线程，直至运行完成，这样可以保证整个函数对外是同步的。</p><p><strong>异步调用同步（async-&gt;fn）</strong>：最外层函数为async，所以要保证整个函数为异步的，可以使用spawn_blocking()的方式：</p><pre><code>pub fn spawn_blocking&lt;F, R&gt;(f: F) -&gt; JoinHandle&lt;R&gt; </code></pre><blockquote><p>Runs the provided closure on a thread where blocking is acceptable.</p></blockquote><p>spawn blocking会使用阻塞线程池上的线程来运行同步函数，调用spawn blocking的函数会让出异步线程让其他Task运行。</p><p>关于block in place，曾向Tokio的作者请教过：<a href="https://github.com/tokio-rs/tokio/discussions/4003">about block in place()</a></p><p><img src="/img/post/block_in_place.png" alt="block in place"></p>]]></content>
    
    
    <categories>
      
      <category>Rust</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Rust</tag>
      
      <tag>Tokio</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Bitcask</title>
    <link href="/2021/12/30/Bitcask/"/>
    <url>/2021/12/30/Bitcask/</url>
    
    <content type="html"><![CDATA[<h1 id="Bitcask"><a href="#Bitcask" class="headerlink" title="Bitcask"></a>Bitcask</h1><h2 id="A-Log-Structured-Fast-KV-Store"><a href="#A-Log-Structured-Fast-KV-Store" class="headerlink" title="A Log-Structured Fast KV Store"></a>A Log-Structured Fast KV Store</h2><p>学习Bitcask的缘由是在Rust中文社区看到了一名高中生正在用Rust实现一个Key-Value数据库系统：Dorea，抱着学习的心态下载了这个项目研究了一下，这个数据库系统使用的存储方案是一个基于hash表结构和key-value的日志型存储模型，名为Bitcask。</p><p>Bitcask起源于一篇同名的数据库模型论文，这篇论文阅读起来没有什么障碍，读完很快就可以理解。豆瓣在2018年就已经基于Bitcask开发了适合于豆瓣使用场景的海量小文件存储系统BeansDB，并成功应用于应用于生产环境，类似的项目还有使用Go语言开发的RoseDB（未应用于生产环境）。</p><p>下面记录一下我对Bitcask的理解，后续会考虑将其应用到Dorea的开发中。</p><hr><p>论文地址：<a href="https://github.com/JesseAtSZ/Bibliography-Collection">Bitcask- A Log-Structured Hash Table for Fast KeyValue Data</a></p><hr><h3 id="日志型的数据文件"><a href="#日志型的数据文件" class="headerlink" title="日志型的数据文件"></a>日志型的数据文件</h3><p>所谓日志型，就是Append only，所有写操作只允许追加新的数据而不允许修改老的数据，就像我们的各种服务器日志一样。</p><p>在Bitcask模型中，数据只增不减地写入文件中，每个文件有一定的大小限制，当文件大小达到到相应的限制时，就会产生一个新的文件并在新的文件中继续进行追加，而老的文件将只读不写。在任意时刻，只有一个文件是可以写入的，Bitcask模型中将当前可以写入的文件称为为Active Data File，而其他的已经达到限制大小的文件，称为Old Data File。</p><p>文件中的数据结构非常简单，每一条数据的结构分别为Key，Value，Key Size，Value Size，Timestamp，Crc校验值，一条条这样格式的数据就组成了数据文件：</p><p><img src="/img/post/Bitcask_Datafiles.png" alt="Bitcask_Datafiles"></p><p>如果数据文件这样持续的存下去，是会无限膨胀的，为了解决个问题，Bitcask有一个定期的Merge操作，定期将所有Old Data File中的数据扫描一遍并生成新的Data File（没有包括Active Data File 是因为它还在不停写入），这里的Merge其实就是将同一个Key的多个数据只保留最新的一个。每次Merge后，新生成的数据文件就不再有冗余数据了。</p><h3 id="基于Hash-Table的索引数据"><a href="#基于Hash-Table的索引数据" class="headerlink" title="基于Hash Table的索引数据"></a>基于Hash Table的索引数据</h3><p>上面讲到的是数据文件，日志类型的数据文件会让我们的写入操作非常快，日志型的优势之一是将磁盘当作磁带，顺序读写的效率非常高，但是如果在这样的日志型数据上使用Key值进行顺序查找，是一件非常低效的事情，所以需要使用一些方法来提高查找效率。</p><p>在Bitcask模型中，使用了一个基于Hash Table的索引数据结构，除了存储在磁盘上的数据文件，还有另外一块数据，那就是存储在内存中的Hash Table，Hash Table的作用是通过Key值快速的定位到Value的位置。Hash Table的结构大致如下图所示：</p><p><img src="/img/post/Bitcask_KeyDir.png" alt="Bitcask_Datafiles"></p><p>Hash Table对应的这个结构中包括了三个用于定位数据Value的信息，分别是文件Id号(FILEID)，Value值在文件中的位置（VPOS），Value值的大小（VSZ），于是我们通过读取FILEID对应文件的VPOS开始的VSZ个字节，就可以得到我们需要的Value值。</p><h3 id="使用Hint-File对索引进行持久化"><a href="#使用Hint-File对索引进行持久化" class="headerlink" title="使用Hint File对索引进行持久化"></a>使用Hint File对索引进行持久化</h3><p>我们称其为索引的Hash Table，是存储在内存中的，Bitcask模型中并不保证在断电或重启后的Hash Table中的索引数据不丢失。</p><p>因此，我们每次启动时需要整个扫描一遍我们的数据文件，重建Hash Table索引，如果数据文件很大，这个重建的过程将非常耗时。因此Bitcask模型中包含了一个称作Hint File的部分，目的在于提高重建Hash Table索引的速度。</p><p>上面讲到在Old Data File进行merge操作时，会产生新的Data File，而Bitcask模型实际还建议同时生成一个Hint File，这个Hint File中每一项的数据结构，与Data file中的数据结构非常相似，不同的是他并不存储具体的Value值，而是存储Value的位置（像在Hash Table中的一样）,Hint File包含Key、Key Size、Value Size、Value Position、Timestamp。</p><p>这样，在重建Hash Table时，就不需要再扫描所有Data File文件，而只需要将Hint File中的数据一行行读取即可，这样就可以大大提高重启数据库的速度。</p><h3 id="更多资料"><a href="#更多资料" class="headerlink" title="更多资料"></a>更多资料</h3><p><a href="https://arpitbhayani.me/blogs/bitcask">Bitcask - A Log-Structured Fast KV Store</a></p><p><a href="https://dorea.mrxzx.info/">Dorea Database</a></p>]]></content>
    
    
    <categories>
      
      <category>Database</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Database</tag>
      
      <tag>Bitcask</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
